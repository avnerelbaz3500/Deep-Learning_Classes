{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST with an MLP, from scratch\n",
    "\n",
    "# - Step 1: build an MLP from scratch to solve MNIST. Question set: https://fleuret.org/dlc/materials/dlc-practical-3.pdf\n",
    "# - Step 2: debug your network with backprop ninja and a reference implementation using torch's .backward()\n",
    "# - Step 3: build the same MLP but will full pytorch code (nn.Linear, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Using MNIST\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:00<00:00, 13.9MB/s]\n",
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 378kB/s]\n",
      "100%|██████████| 1.65M/1.65M [00:00<00:00, 3.23MB/s]\n",
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 6.05MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Reduce the data-set (use --full for the full thing)\n",
      "** Use 1000 train and 1000 test samples\n"
     ]
    }
   ],
   "source": [
    "train_input, train_target, test_input, test_target = load_data(one_hot_labels = True, normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAG/9JREFUeJzt3X9w1PW97/HXBsgCmiyGmF8SaEABK5DeIqQ5KMWSQ0jnUhDOGUD/AIcDFxo8hdTqpFdBW2fS4qm1OhF65rak3hGwzBG4cs6hA8GEsU1wQLkMU5tDMlHgkgTlTrIhSAjJ5/7BdT0rAfpddvPOhudj5jtDdr/vfD98u/XJl9188TnnnAAA6GMJ1gsAANyeCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADAx2HoBX9XT06OzZ88qKSlJPp/PejkAAI+cc2pvb1dWVpYSEq5/ndPvAnT27FllZ2dbLwMAcItOnz6tUaNGXff5fhegpKQkSdJD+q4Ga4jxagAAXl1Rl97Tv4X+e349MQtQeXm5XnrpJTU3Nys3N1evvfaapk+fftO5L/7abbCGaLCPAAFA3Pn/dxi92dsoMfkQwltvvaWSkhJt3LhRH3zwgXJzc1VYWKhz587F4nAAgDgUkwC9/PLLWrlypZ544gl9/etf15YtWzR8+HD99re/jcXhAABxKOoBunz5so4ePaqCgoIvD5KQoIKCAtXU1Fyzf2dnp4LBYNgGABj4oh6gzz77TN3d3UpPTw97PD09Xc3NzdfsX1ZWpkAgENr4BBwA3B7MfxC1tLRUbW1toe306dPWSwIA9IGofwouNTVVgwYNUktLS9jjLS0tysjIuGZ/v98vv98f7WUAAPq5qF8BJSYmaurUqaqsrAw91tPTo8rKSuXn50f7cACAOBWTnwMqKSnRsmXL9OCDD2r69Ol65ZVX1NHRoSeeeCIWhwMAxKGYBGjx4sX69NNPtWHDBjU3N+sb3/iG9u3bd80HEwAAty+fc85ZL+I/CwaDCgQCmqX53AkBAOLQFdelKu1RW1ubkpOTr7uf+afgAAC3JwIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYCLqAXr++efl8/nCtokTJ0b7MACAODc4Ft/0gQce0IEDB748yOCYHAYAEMdiUobBgwcrIyMjFt8aADBAxOQ9oJMnTyorK0tjx47V448/rlOnTl13387OTgWDwbANADDwRT1AeXl5qqio0L59+7R582Y1Njbq4YcfVnt7e6/7l5WVKRAIhLbs7OxoLwkA0A/5nHMulgdobW3VmDFj9PLLL2vFihXXPN/Z2anOzs7Q18FgUNnZ2Zql+RrsGxLLpQEAYuCK61KV9qitrU3JycnX3S/mnw4YMWKExo8fr/r6+l6f9/v98vv9sV4GAKCfifnPAV24cEENDQ3KzMyM9aEAAHEk6gF66qmnVF1drY8//lh/+tOf9Oijj2rQoEFaunRptA8FAIhjUf8ruDNnzmjp0qU6f/687r77bj300EOqra3V3XffHe1DAQDiWNQDtGPHjmh/SwDAAMS94AAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEzH/B+mAeHK58EHPM5883uN5Zs03qz3PrLvrPzzPRGry/3jS88zwJu//uHLr33TefKevGPOm9z83J/7hiOcZxB5XQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADDB3bAxIH26Oj+iudeeLvc886C/2/NMQgR/9lv2cYHnmf8SOOV5RpL+9z/8KqI5ryI5D3+TstTzTMofPI+gD3AFBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCY4Gak6FO+IYmeZy4V5Hqe+ZfSlzzPSFLWYL/nmRWf/K3nmU/+aYLnmTv+9ZjnmXeHj/Y8I0nVu8Z7nvmX+/5XRMfyKnhspOeZlBisA7eOKyAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQ3I0Wfalr7oOeZ95/6VQRH8n5TUUn6+/p5nmeuLOryPDP8s8OeZ5znCensqqkRTEmH74vknHv37xeTPM/c++vTnmeueJ5AX+AKCABgggABAEx4DtChQ4c0b948ZWVlyefzaffu3WHPO+e0YcMGZWZmatiwYSooKNDJkyejtV4AwADhOUAdHR3Kzc1VeXl5r89v2rRJr776qrZs2aLDhw/rjjvuUGFhoS5dunTLiwUADByeP4RQVFSkoqKiXp9zzumVV17Rs88+q/nz50uS3njjDaWnp2v37t1asmTJra0WADBgRPU9oMbGRjU3N6ugoCD0WCAQUF5enmpqanqd6ezsVDAYDNsAAANfVAPU3NwsSUpPTw97PD09PfTcV5WVlSkQCIS27OzsaC4JANBPmX8KrrS0VG1tbaHt9Gnvn/EHAMSfqAYoIyNDktTS0hL2eEtLS+i5r/L7/UpOTg7bAAADX1QDlJOTo4yMDFVWVoYeCwaDOnz4sPLz86N5KABAnPP8KbgLFy6ovr4+9HVjY6OOHTumlJQUjR49WuvWrdOLL76o++67Tzk5OXruueeUlZWlBQsWRHPdAIA45zlAR44c0SOPPBL6uqSkRJK0bNkyVVRU6Omnn1ZHR4dWrVql1tZWPfTQQ9q3b5+GDh0avVUDAOKezzkXyT0OYyYYDCoQCGiW5muwb4j1cnADJ1/L8zxTt/B1zzM96vE8c//+1Z5nJGniUx97nun+7HxEx+oLj/7504jmngh8HN2FXMfD//0fPc/cVdH7j3Sg/7jiulSlPWpra7vh+/rmn4IDANyeCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYMLzP8eAgafhF9+KaK5uYbnnmbaeS55n/v4vj3memfDkf3iekaTu9vaI5rxKuOMOzzPn/26K55n5d77keUaSEjTM88zEncWeZ+7lzta3Na6AAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAAT3Ix0gBmUnuZ55nePvh7RsXrU43kmkhuLJv7tJ55nvK8scgnf+LrnmUm//cjzzIvpr3qekfwRzEgzji3xPDPhee+/p27PExhIuAICAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAExwM9IBxjfU+80nH/T33S0hh/1joucZ35hszzMnV4/yPCNJcwo+8DyzPu2fPc+MHjzM80wkN1jtdi6CKcn3Vqr3Y7WejOhYuH1xBQQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmOBmpAOMu9TpeeZw55CIjpXn7/I8s+fADs8zPRHdhrPvHPjc+407T3Z5v0noI8MueJ45ctn7zV8lacQbNRHNAV5wBQQAMEGAAAAmPAfo0KFDmjdvnrKysuTz+bR79+6w55cvXy6fzxe2zZ07N1rrBQAMEJ4D1NHRodzcXJWXl193n7lz56qpqSm0bd++/ZYWCQAYeDx/CKGoqEhFRUU33Mfv9ysjIyPiRQEABr6YvAdUVVWltLQ0TZgwQWvWrNH58+evu29nZ6eCwWDYBgAY+KIeoLlz5+qNN95QZWWlfv7zn6u6ulpFRUXq7u7udf+ysjIFAoHQlp2dHe0lAQD6oaj/HNCSJUtCv548ebKmTJmicePGqaqqSrNnz75m/9LSUpWUlIS+DgaDRAgAbgMx/xj22LFjlZqaqvr6+l6f9/v9Sk5ODtsAAANfzAN05swZnT9/XpmZmbE+FAAgjnj+K7gLFy6EXc00Njbq2LFjSklJUUpKil544QUtWrRIGRkZamho0NNPP617771XhYWFUV04ACC+eQ7QkSNH9Mgjj4S+/uL9m2XLlmnz5s06fvy4fve736m1tVVZWVmaM2eOfvrTn8rv90dv1QCAuOdzznm/K2IMBYNBBQIBzdJ8DfZFdpNMeHO58MGI5v5py+ueZ6YkDvI880bwHs8zL1Z/z/OMJI2vuOR5ZnBLm+eZtO3/1/PMluyDnmcm7lvjeUaSxq84EtEcIElXXJeqtEdtbW03fF+fe8EBAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADARNT/SW7En8Q/RHbn4x/nTI/ySqJnvN7vs2O1z/d+Hv519B7PM13O+58Xh32c6HkG6CtcAQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJrgZKXCLrgzz/ue4LtfteaZHPZ5ncipOeZ6RpCsRTQHecAUEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJjgZqTALUraUet96BfRXwcQb7gCAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMcDNS4Ba1L/lWBFNHo74OIN5wBQQAMEGAAAAmPAWorKxM06ZNU1JSktLS0rRgwQLV1dWF7XPp0iUVFxdr5MiRuvPOO7Vo0SK1tLREddEAgPjnKUDV1dUqLi5WbW2t9u/fr66uLs2ZM0cdHR2hfdavX6933nlHO3fuVHV1tc6ePauFCxdGfeEAgPjm6UMI+/btC/u6oqJCaWlpOnr0qGbOnKm2tjb95je/0bZt2/Sd73xHkrR161bdf//9qq2t1be+FcmbtQCAgeiW3gNqa2uTJKWkpEiSjh49qq6uLhUUFIT2mThxokaPHq2amppev0dnZ6eCwWDYBgAY+CIOUE9Pj9atW6cZM2Zo0qRJkqTm5mYlJiZqxIgRYfump6erubm51+9TVlamQCAQ2rKzsyNdEgAgjkQcoOLiYp04cUI7duy4pQWUlpaqra0ttJ0+ffqWvh8AID5E9IOoa9eu1d69e3Xo0CGNGjUq9HhGRoYuX76s1tbWsKuglpYWZWRk9Pq9/H6//H5/JMsAAMQxT1dAzjmtXbtWu3bt0sGDB5WTkxP2/NSpUzVkyBBVVlaGHqurq9OpU6eUn58fnRUDAAYET1dAxcXF2rZtm/bs2aOkpKTQ+zqBQEDDhg1TIBDQihUrVFJSopSUFCUnJ+vJJ59Ufn4+n4ADAITxFKDNmzdLkmbNmhX2+NatW7V8+XJJ0i9/+UslJCRo0aJF6uzsVGFhoV5//fWoLBYAMHB4CpBz7qb7DB06VOXl5SovL494UUA8aRvLHa2ASPD/HACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJiI6F9EBfCle6ovep4ZsnaQ55mum9+MHogrXAEBAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACa4GSlwi3x/POZ5piKY5nlmadL/8Txz8YFMzzOSlHj6TERzgBdcAQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJrgZKWDgl7/+O88zS5/6leeZzOfqPc9I0vnWKd6Hao9HdCzcvrgCAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMcDNSwMA9/7PO88ziBf/V88xb9+71PCNJ396w1PNMymMBzzPdrW2eZzBwcAUEADBBgAAAJjwFqKysTNOmTVNSUpLS0tK0YMEC1dWF/1XCrFmz5PP5wrbVq1dHddEAgPjnKUDV1dUqLi5WbW2t9u/fr66uLs2ZM0cdHR1h+61cuVJNTU2hbdOmTVFdNAAg/nn6EMK+ffvCvq6oqFBaWpqOHj2qmTNnhh4fPny4MjIyorNCAMCAdEvvAbW1Xf0ES0pKStjjb775plJTUzVp0iSVlpbq4sWL1/0enZ2dCgaDYRsAYOCL+GPYPT09WrdunWbMmKFJkyaFHn/sscc0ZswYZWVl6fjx43rmmWdUV1ent99+u9fvU1ZWphdeeCHSZQAA4lTEASouLtaJEyf03nvvhT2+atWq0K8nT56szMxMzZ49Ww0NDRo3btw136e0tFQlJSWhr4PBoLKzsyNdFgAgTkQUoLVr12rv3r06dOiQRo0adcN98/LyJEn19fW9Bsjv98vv90eyDABAHPMUIOecnnzySe3atUtVVVXKycm56cyxY8ckSZmZmREtEAAwMHkKUHFxsbZt26Y9e/YoKSlJzc3NkqRAIKBhw4apoaFB27Zt03e/+12NHDlSx48f1/r16zVz5kxNmTIlJr8BAEB88hSgzZs3S7r6w6b/2datW7V8+XIlJibqwIEDeuWVV9TR0aHs7GwtWrRIzz77bNQWDAAYGDz/FdyNZGdnq7q6+pYWBAC4PXA3bMBA92fnPc9cXjTS88z9v/hvnmck6aOCX3ue+d7EFd4PVHvc+wwGDG5GCgAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCY4GakQJyI5Aam9y3zPiNJ39O0CKa4sSi84QoIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACAiX53LzjnnCTpirokZ7wYAIBnV9Ql6cv/nl9PvwtQe3u7JOk9/ZvxSgAAt6K9vV2BQOC6z/vczRLVx3p6enT27FklJSXJ5/OFPRcMBpWdna3Tp08rOTnZaIX2OA9XcR6u4jxcxXm4qj+cB+ec2tvblZWVpYSE67/T0++ugBISEjRq1Kgb7pOcnHxbv8C+wHm4ivNwFefhKs7DVdbn4UZXPl/gQwgAABMECABgIq4C5Pf7tXHjRvn9fuulmOI8XMV5uIrzcBXn4ap4Og/97kMIAIDbQ1xdAQEABg4CBAAwQYAAACYIEADARNwEqLy8XF/72tc0dOhQ5eXl6f3337deUp97/vnn5fP5wraJEydaLyvmDh06pHnz5ikrK0s+n0+7d+8Oe945pw0bNigzM1PDhg1TQUGBTp48abPYGLrZeVi+fPk1r4+5c+faLDZGysrKNG3aNCUlJSktLU0LFixQXV1d2D6XLl1ScXGxRo4cqTvvvFOLFi1SS0uL0Ypj4685D7Nmzbrm9bB69WqjFfcuLgL01ltvqaSkRBs3btQHH3yg3NxcFRYW6ty5c9ZL63MPPPCAmpqaQtt7771nvaSY6+joUG5ursrLy3t9ftOmTXr11Ve1ZcsWHT58WHfccYcKCwt16dKlPl5pbN3sPEjS3Llzw14f27dv78MVxl51dbWKi4tVW1ur/fv3q6urS3PmzFFHR0don/Xr1+udd97Rzp07VV1drbNnz2rhwoWGq46+v+Y8SNLKlSvDXg+bNm0yWvF1uDgwffp0V1xcHPq6u7vbZWVlubKyMsNV9b2NGze63Nxc62WYkuR27doV+rqnp8dlZGS4l156KfRYa2ur8/v9bvv27QYr7BtfPQ/OObds2TI3f/58k/VYOXfunJPkqqurnXNX/7cfMmSI27lzZ2ifjz76yElyNTU1VsuMua+eB+ec+/a3v+1+8IMf2C3qr9Dvr4AuX76so0ePqqCgIPRYQkKCCgoKVFNTY7gyGydPnlRWVpbGjh2rxx9/XKdOnbJekqnGxkY1NzeHvT4CgYDy8vJuy9dHVVWV0tLSNGHCBK1Zs0bnz5+3XlJMtbW1SZJSUlIkSUePHlVXV1fY62HixIkaPXr0gH49fPU8fOHNN99UamqqJk2apNLSUl28eNFiedfV725G+lWfffaZuru7lZ6eHvZ4enq6/vKXvxitykZeXp4qKio0YcIENTU16YUXXtDDDz+sEydOKCkpyXp5JpqbmyWp19fHF8/dLubOnauFCxcqJydHDQ0N+vGPf6yioiLV1NRo0KBB1suLup6eHq1bt04zZszQpEmTJF19PSQmJmrEiBFh+w7k10Nv50GSHnvsMY0ZM0ZZWVk6fvy4nnnmGdXV1entt982XG24fh8gfKmoqCj06ylTpigvL09jxozR73//e61YscJwZegPlixZEvr15MmTNWXKFI0bN05VVVWaPXu24cpio7i4WCdOnLgt3ge9keudh1WrVoV+PXnyZGVmZmr27NlqaGjQuHHj+nqZver3fwWXmpqqQYMGXfMplpaWFmVkZBitqn8YMWKExo8fr/r6euulmPniNcDr41pjx45VamrqgHx9rF27Vnv37tW7774b9s+3ZGRk6PLly2ptbQ3bf6C+Hq53HnqTl5cnSf3q9dDvA5SYmKipU6eqsrIy9FhPT48qKyuVn59vuDJ7Fy5cUENDgzIzM62XYiYnJ0cZGRlhr49gMKjDhw/f9q+PM2fO6Pz58wPq9eGc09q1a7Vr1y4dPHhQOTk5Yc9PnTpVQ4YMCXs91NXV6dSpUwPq9XCz89CbY8eOSVL/ej1Yfwrir7Fjxw7n9/tdRUWF+/Of/+xWrVrlRowY4Zqbm62X1qd++MMfuqqqKtfY2Oj++Mc/uoKCApeamurOnTtnvbSYam9vdx9++KH78MMPnST38ssvuw8//NB98sknzjnnfvazn7kRI0a4PXv2uOPHj7v58+e7nJwc9/nnnxuvPLpudB7a29vdU0895WpqalxjY6M7cOCA++Y3v+nuu+8+d+nSJeulR82aNWtcIBBwVVVVrqmpKbRdvHgxtM/q1avd6NGj3cGDB92RI0dcfn6+y8/PN1x19N3sPNTX17uf/OQn7siRI66xsdHt2bPHjR071s2cOdN45eHiIkDOOffaa6+50aNHu8TERDd9+nRXW1trvaQ+t3jxYpeZmekSExPdPffc4xYvXuzq6+utlxVz7777rpN0zbZs2TLn3NWPYj/33HMuPT3d+f1+N3v2bFdXV2e76Bi40Xm4ePGimzNnjrv77rvdkCFD3JgxY9zKlSsH3B/Sevv9S3Jbt24N7fP555+773//++6uu+5yw4cPd48++qhramqyW3QM3Ow8nDp1ys2cOdOlpKQ4v9/v7r33XvejH/3ItbW12S78K/jnGAAAJvr9e0AAgIGJAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADDx/wD8WaYl67FxSwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_input[4].view((28,28)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy (preds, targets):\n",
    "    \"\"\" Computes the accuracy between predictions and targets. Data is expected to be one-hot encoded. \"\"\"\n",
    "    _, idx1 = torch.max(preds, dim=1)\n",
    "    _, idx2 = torch.max(targets, dim=1)\n",
    "    d = idx1 == idx2\n",
    "    return d.int().float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unit test\n",
    "# this cell should return 0.75\n",
    "preds = torch.zeros((4,7))\n",
    "preds[0,1] = 1\n",
    "preds[1,4] = 1\n",
    "preds[2,2] = 1\n",
    "preds[3,6] = 1\n",
    "targets = torch.zeros((4,7))\n",
    "targets[0,1] = 1\n",
    "targets[1,4] = 1\n",
    "targets[2,2] = 1\n",
    "targets[3,2] = 1\n",
    "compute_accuracy(preds, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma(x):\n",
    "    return torch.tanh(x)\n",
    "\n",
    "def dsigma(x):\n",
    "    y = torch.tanh(x)\n",
    "    return 1.0 - y ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss (v,t):\n",
    "    diff = v - t\n",
    "    return (diff ** 2).mean()\n",
    "\n",
    "\n",
    "def dloss(v, t):\n",
    "    diff = v - t\n",
    "    return 2.0 * diff / diff.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0186, -0.1486, -0.2336, -0.0698,  0.1179, -0.0866],\n",
       "        [ 0.1346,  0.1107, -0.0309, -0.1900, -0.1738, -0.0628],\n",
       "        [ 0.1250, -0.0219, -0.0471, -0.1167, -0.1283, -0.1639]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "v = torch.randn((3, 6), dtype=torch.float32)\n",
    "t = torch.randn((3, 6), dtype=torch.float32)\n",
    "l=loss(v,t)\n",
    "dloss(v,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiply targets by 0.9 to be in the range of tanh\n",
    "train_target *= 0.9\n",
    "test_target *= 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Backprop ninja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function we will use later when comparing manual gradients to PyTorch gradients\n",
    "# DO NOT MODIFY IT\n",
    "#\n",
    "def cmp(s, dt, t):\n",
    "  ex = torch.all(dt == t.grad).item()\n",
    "  app = torch.allclose(dt, t.grad)\n",
    "  maxdiff = (dt - t.grad).abs().max().item()\n",
    "  print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "w1 = torch.randn((784, 50)) / math.sqrt(784)\n",
    "w2 = torch.randn((50, 10)) / math.sqrt(50)\n",
    "b1 = torch.zeros((50,))\n",
    "b2 = torch.zeros((10,))\n",
    "parameters = [w1, b1, w2, b2]\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 10]), tensor(0.3172, grad_fn=<MeanBackward0>))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = train_input[:5]\n",
    "y1 = train_target[:5]\n",
    "\n",
    "z1 = x1 @ w1 + b1\n",
    "h1 = sigma(z1)   \n",
    "\n",
    "z2 = h1 @ w2 + b2\n",
    "h2 = sigma(z2)\n",
    "\n",
    "l = loss(h2, y1)\n",
    "\n",
    "l = loss(h2, y1)\n",
    "h2.shape, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=0.3172305226325989\n"
     ]
    }
   ],
   "source": [
    "# Force pytorch to retain grade for intermediate nodes and reset grad for parameters\n",
    "# DO NOT MODIFY THIS CODE\n",
    "#\n",
    "others = [h2,z2,h1,z1]\n",
    "for p in parameters:\n",
    "    p.grad = None\n",
    "for t in others:\n",
    "    t.retain_grad()\n",
    "l.backward()\n",
    "print(f'loss={l}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2.grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h2              | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n",
      "z2              | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n",
      "w2              | exact: False | approximate: True  | maxdiff: 7.450580596923828e-09\n",
      "b2              | exact: False | approximate: True  | maxdiff: 1.1175870895385742e-08\n",
      "h1              | exact: False | approximate: True  | maxdiff: 2.7939677238464355e-09\n",
      "z1              | exact: False | approximate: True  | maxdiff: 2.7939677238464355e-09\n",
      "w1              | exact: False | approximate: True  | maxdiff: 1.4901161193847656e-08\n",
      "b1              | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n"
     ]
    }
   ],
   "source": [
    "# here we compare our gradient to the reference gradient computed by pytorch\n",
    "dl = 1.0\n",
    "\n",
    "# sortie -> loss\n",
    "dh2 = dloss(h2, y1) * dl\n",
    "cmp('h2', dh2, h2)\n",
    "\n",
    "# à travers tanh de la 2e couche\n",
    "dz2 = dsigma(z2) * dh2\n",
    "cmp('z2', dz2, z2)\n",
    "\n",
    "# à travers la linéaire 2\n",
    "dw2 = h1.T @ dz2\n",
    "cmp('w2', dw2, w2)\n",
    "\n",
    "db2 = dz2.sum(dim=0)\n",
    "cmp('b2', db2, b2)\n",
    "\n",
    "dh1 = dz2 @ w2.T\n",
    "cmp('h1', dh1, h1)\n",
    "\n",
    "dz1 = dsigma(z1) * dh1\n",
    "cmp('z1', dz1, z1)\n",
    "\n",
    "dw1 = x1.T @ dz1\n",
    "cmp('w1', dw1, w1)\n",
    "\n",
    "db1 = dz1.sum(dim=0)\n",
    "cmp('b1', db1, b1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "with torch.no_grad():\n",
    "    w1 += -lr * dw1\n",
    "    b1 += -lr * db1.squeeze()\n",
    "    w2 += -lr * dw2\n",
    "    b2 += -lr * db2.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3172305226325989"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = loss(h2, y1)\n",
    "l.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now that we've checked our gradients are correct, we can implement the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(w1, b1, w2, b2, x):\n",
    "    z1 = x @ w1 + b1\n",
    "    h1 = sigma(z1)\n",
    "    z2 = h1 @ w2 + b2\n",
    "    h2 = sigma(z2)\n",
    "    return z1, h1, z2, h2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(w1, b1, w2, b2, x1, y1, h2, z2, h1, z1):\n",
    "    dl = 1.0\n",
    "    dh2 = dloss(h2, y1) * dl\n",
    "    dz2 = dsigma(z2) * dh2\n",
    "    dw2 = h1.T @ dz2\n",
    "    db2 = dz2.sum(dim=0)\n",
    "    dh1 = dz2 @ w2.T\n",
    "    dz1 = dsigma(z1) * dh1\n",
    "    dw1 = x1.T @ dz1\n",
    "    db1 = dz1.sum(dim=0)\n",
    "    return dw1, db1, dw2, db2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w2              | exact: False | approximate: True  | maxdiff: 5.587935447692871e-09\n",
      "b2              | exact: False | approximate: True  | maxdiff: 7.450580596923828e-09\n",
      "w1              | exact: False | approximate: True  | maxdiff: 1.4901161193847656e-08\n",
      "b1              | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n"
     ]
    }
   ],
   "source": [
    "#Test added for sanity check on backward\n",
    "\n",
    "z1, h1, z2, h2 = forward(w1, b1, w2, b2, x1)\n",
    "l = loss(h2, y1)\n",
    "for p in [w1, b1, w2, b2]:\n",
    "    p.grad = None\n",
    "for t in [h2, z2, h1, z1]:\n",
    "    t.grad = None\n",
    "    t.retain_grad()\n",
    "l.backward()\n",
    "\n",
    "dw1_m, db1_m, dw2_m, db2_m = backward(w1, b1, w2, b2, x1, y1, h2, z2, h1, z1)\n",
    "\n",
    "cmp('w2', dw2_m, w2)\n",
    "cmp('b2', db2_m, b2)\n",
    "cmp('w1', dw1_m, w1)\n",
    "cmp('b1', db1_m, b1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(w1, b1, w2, b2, dw1, db1, dw2, db2, lr):\n",
    "    with torch.no_grad():\n",
    "        w1 += -lr * dw1\n",
    "        b1 += -lr * db1\n",
    "        w2 += -lr * dw2\n",
    "        b2 += -lr * db2\n",
    "    return w1, b1, w2, b2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init():\n",
    "    \"\"\" init a network \"\"\"\n",
    "    n_in = 784\n",
    "    n_hidden = 50\n",
    "    n_out = 10\n",
    "\n",
    "    w1 = torch.randn((n_in, n_hidden)) / math.sqrt(n_in)\n",
    "    b1 = torch.zeros((n_hidden,))\n",
    "    w2 = torch.randn((n_hidden, n_out)) / math.sqrt(n_hidden)\n",
    "    b2 = torch.zeros((n_out,))\n",
    "\n",
    "    return w1, b1, w2, b2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, b1, w2, b2 = init()\n",
    "parameters = [w1, b1, w2, b2]\n",
    "for p in parameters:\n",
    "    p.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(linewidth=200)\n",
    "\n",
    "def train(w1, b1, w2, b2):\n",
    "    lossi = []\n",
    "    for step in range(10000):\n",
    "        xb = train_input\n",
    "        yb = train_target\n",
    "        num_samples = xb.shape[0]\n",
    "\n",
    "        z1, h1, z2, h2 = forward(w1, b1, w2, b2, xb)\n",
    "        lsi = loss(h2, yb)\n",
    "\n",
    "        dw1, db1, dw2, db2 = backward(w1, b1, w2, b2, xb, yb, h2, z2, h1, z1)\n",
    "\n",
    "        lr = 0.1 / num_samples if step < 5000 else 0.01 / num_samples\n",
    "        w1, b1, w2, b2 = update(w1, b1, w2, b2, dw1, db1, dw2, db2, lr)\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            print(f'step = {step}, loss = {lsi}')\n",
    "        lossi.append(lsi.item())\n",
    "\n",
    "    _, _, _, preds = forward(w1, b1, w2, b2, train_input)\n",
    "    train_accuracy = compute_accuracy(preds, train_target)\n",
    "    _, _, _, preds = forward(w1, b1, w2, b2, test_input)\n",
    "    test_accuracy = compute_accuracy(preds, test_target)\n",
    "    print(f'{train_accuracy=}')\n",
    "    print(f'{test_accuracy=}')\n",
    "    return lossi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 0, loss = 0.2870658338069916\n",
      "step = 100, loss = 0.28026241064071655\n",
      "step = 200, loss = 0.27386602759361267\n",
      "step = 300, loss = 0.2678620517253876\n",
      "step = 400, loss = 0.26223164796829224\n",
      "step = 500, loss = 0.2569533586502075\n",
      "step = 600, loss = 0.25200363993644714\n",
      "step = 700, loss = 0.2473577857017517\n",
      "step = 800, loss = 0.242990642786026\n",
      "step = 900, loss = 0.23887763917446136\n",
      "step = 1000, loss = 0.23499491810798645\n",
      "step = 1100, loss = 0.2313203662633896\n",
      "step = 1200, loss = 0.2278331071138382\n",
      "step = 1300, loss = 0.2245141565799713\n",
      "step = 1400, loss = 0.2213463932275772\n",
      "step = 1500, loss = 0.2183144986629486\n",
      "step = 1600, loss = 0.21540498733520508\n",
      "step = 1700, loss = 0.21260610222816467\n",
      "step = 1800, loss = 0.2099073976278305\n",
      "step = 1900, loss = 0.2073000967502594\n",
      "step = 2000, loss = 0.20477642118930817\n",
      "step = 2100, loss = 0.20232973992824554\n",
      "step = 2200, loss = 0.19995465874671936\n",
      "step = 2300, loss = 0.1976461261510849\n",
      "step = 2400, loss = 0.19540010392665863\n",
      "step = 2500, loss = 0.19321313500404358\n",
      "step = 2600, loss = 0.191082164645195\n",
      "step = 2700, loss = 0.1890045702457428\n",
      "step = 2800, loss = 0.1869780272245407\n",
      "step = 2900, loss = 0.1850007027387619\n",
      "step = 3000, loss = 0.18307070434093475\n",
      "step = 3100, loss = 0.18118631839752197\n",
      "step = 3200, loss = 0.1793462336063385\n",
      "step = 3300, loss = 0.17754900455474854\n",
      "step = 3400, loss = 0.17579345405101776\n",
      "step = 3500, loss = 0.17407836019992828\n",
      "step = 3600, loss = 0.1724025458097458\n",
      "step = 3700, loss = 0.1707649528980255\n",
      "step = 3800, loss = 0.16916456818580627\n",
      "step = 3900, loss = 0.16760031878948212\n",
      "step = 4000, loss = 0.16607128083705902\n",
      "step = 4100, loss = 0.16457635164260864\n",
      "step = 4200, loss = 0.16311463713645935\n",
      "step = 4300, loss = 0.16168536245822906\n",
      "step = 4400, loss = 0.16028743982315063\n",
      "step = 4500, loss = 0.15891993045806885\n",
      "step = 4600, loss = 0.15758199989795685\n",
      "step = 4700, loss = 0.15627291798591614\n",
      "step = 4800, loss = 0.15499179065227509\n",
      "step = 4900, loss = 0.15373766422271729\n",
      "step = 5000, loss = 0.15250980854034424\n",
      "step = 5100, loss = 0.15238840878009796\n",
      "step = 5200, loss = 0.15226727724075317\n",
      "step = 5300, loss = 0.1521463692188263\n",
      "step = 5400, loss = 0.1520257145166397\n",
      "step = 5500, loss = 0.15190532803535461\n",
      "step = 5600, loss = 0.151785209774971\n",
      "step = 5700, loss = 0.1516653448343277\n",
      "step = 5800, loss = 0.1515457034111023\n",
      "step = 5900, loss = 0.151426300406456\n",
      "step = 6000, loss = 0.15130718052387238\n",
      "step = 6100, loss = 0.15118828415870667\n",
      "step = 6200, loss = 0.15106967091560364\n",
      "step = 6300, loss = 0.1509513109922409\n",
      "step = 6400, loss = 0.15083323419094086\n",
      "step = 6500, loss = 0.1507153958082199\n",
      "step = 6600, loss = 0.15059778094291687\n",
      "step = 6700, loss = 0.15048037469387054\n",
      "step = 6800, loss = 0.15036320686340332\n",
      "step = 6900, loss = 0.15024630725383759\n",
      "step = 7000, loss = 0.15012966096401215\n",
      "step = 7100, loss = 0.15001323819160461\n",
      "step = 7200, loss = 0.149897038936615\n",
      "step = 7300, loss = 0.14978113770484924\n",
      "step = 7400, loss = 0.1496654599905014\n",
      "step = 7500, loss = 0.14955000579357147\n",
      "step = 7600, loss = 0.14943476021289825\n",
      "step = 7700, loss = 0.14931978285312653\n",
      "step = 7800, loss = 0.1492050588130951\n",
      "step = 7900, loss = 0.14909055829048157\n",
      "step = 8000, loss = 0.14897629618644714\n",
      "step = 8100, loss = 0.14886225759983063\n",
      "step = 8200, loss = 0.1487484872341156\n",
      "step = 8300, loss = 0.1486349105834961\n",
      "step = 8400, loss = 0.14852158725261688\n",
      "step = 8500, loss = 0.148408442735672\n",
      "step = 8600, loss = 0.1482955515384674\n",
      "step = 8700, loss = 0.14818288385868073\n",
      "step = 8800, loss = 0.14807046949863434\n",
      "step = 8900, loss = 0.14795827865600586\n",
      "step = 9000, loss = 0.14784635603427887\n",
      "step = 9100, loss = 0.14773467183113098\n",
      "step = 9200, loss = 0.1476232260465622\n",
      "step = 9300, loss = 0.14751200377941132\n",
      "step = 9400, loss = 0.14740099012851715\n",
      "step = 9500, loss = 0.14729025959968567\n",
      "step = 9600, loss = 0.1471797674894333\n",
      "step = 9700, loss = 0.14706945419311523\n",
      "step = 9800, loss = 0.1469593644142151\n",
      "step = 9900, loss = 0.14684946835041046\n",
      "train_accuracy=0.22599999606609344\n",
      "test_accuracy=0.2240000069141388\n"
     ]
    }
   ],
   "source": [
    "lossi = train(w1, b1, w2, b2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lossi)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Reference implementation using pytorch's .backward()\n",
    "Nothing to do in Step 2, this code is provided for you as a reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, b1, w2, b2 = init()\n",
    "parameters = [w1, b1, w2, b2]\n",
    "for p in parameters:\n",
    "    p.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference code\n",
    "torch.set_printoptions(linewidth=200)\n",
    "import torch.nn as F\n",
    "\n",
    "def train(w1, b1, w2, b2):\n",
    "    lossi = []\n",
    "    for step in range(10000):\n",
    "        xb = train_input\n",
    "        yb = train_target\n",
    "        num_samples = xb.shape[0]\n",
    "        # forward\n",
    "        z1, h1, z2, h2 = forward(w1, b1, w2, b2, xb)\n",
    "        xloss = F.MSELoss()\n",
    "        lsi = xloss(h2, yb) * yb.nelement()\n",
    "        # backward\n",
    "        for p in parameters:\n",
    "            p.grad = None\n",
    "        lsi.backward()\n",
    "        # update\n",
    "        lr = 0.1 / num_samples\n",
    "        for p in parameters:\n",
    "            p.data += -lr * p.grad\n",
    "        if step % 100 == 0: print(f'step = {step}, loss = {lsi}')\n",
    "        lossi.append(lsi.item())\n",
    "    # compute accuracy\n",
    "    _, _, _, preds = forward(w1, b1, w2, b2, train_input)\n",
    "    train_accuracy = compute_accuracy(preds, train_target)\n",
    "    _, _, _, preds = forward(w1, b1, w2, b2, test_input)\n",
    "    test_accuracy = compute_accuracy(preds, test_target)\n",
    "    print(f'{train_accuracy=}')\n",
    "    print(f'{test_accuracy=}')\n",
    "    return lossi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 0, loss = 3035.796875\n",
      "step = 100, loss = 256.0908203125\n",
      "step = 200, loss = 210.29698181152344\n",
      "step = 300, loss = 150.6993865966797\n",
      "step = 400, loss = 110.96878051757812\n",
      "step = 500, loss = 123.93833923339844\n",
      "step = 600, loss = 115.63629150390625\n",
      "step = 700, loss = 74.19902038574219\n",
      "step = 800, loss = 81.29428100585938\n",
      "step = 900, loss = 67.43013000488281\n",
      "step = 1000, loss = 63.499778747558594\n",
      "step = 1100, loss = 60.79499435424805\n",
      "step = 1200, loss = 68.59199523925781\n",
      "step = 1300, loss = 55.96957778930664\n",
      "step = 1400, loss = 59.43489074707031\n",
      "step = 1500, loss = 46.593894958496094\n",
      "step = 1600, loss = 56.25494384765625\n",
      "step = 1700, loss = 55.72847366333008\n",
      "step = 1800, loss = 49.16326904296875\n",
      "step = 1900, loss = 32.94535446166992\n",
      "step = 2000, loss = 45.33491516113281\n",
      "step = 2100, loss = 36.3771858215332\n",
      "step = 2200, loss = 46.8979606628418\n",
      "step = 2300, loss = 42.26640701293945\n",
      "step = 2400, loss = 39.19702911376953\n",
      "step = 2500, loss = 43.66585922241211\n",
      "step = 2600, loss = 43.145381927490234\n",
      "step = 2700, loss = 38.248748779296875\n",
      "step = 2800, loss = 42.887577056884766\n",
      "step = 2900, loss = 32.36246871948242\n",
      "step = 3000, loss = 33.04034423828125\n",
      "step = 3100, loss = 23.473392486572266\n",
      "step = 3200, loss = 36.479652404785156\n",
      "step = 3300, loss = 36.59977340698242\n",
      "step = 3400, loss = 25.87251091003418\n",
      "step = 3500, loss = 35.91185760498047\n",
      "step = 3600, loss = 20.94805908203125\n",
      "step = 3700, loss = 22.026777267456055\n",
      "step = 3800, loss = 30.154695510864258\n",
      "step = 3900, loss = 21.370372772216797\n",
      "step = 4000, loss = 21.250324249267578\n",
      "step = 4100, loss = 27.003070831298828\n",
      "step = 4200, loss = 18.306869506835938\n",
      "step = 4300, loss = 26.65423011779785\n",
      "step = 4400, loss = 24.303447723388672\n",
      "step = 4500, loss = 21.362228393554688\n",
      "step = 4600, loss = 24.99037742614746\n",
      "step = 4700, loss = 22.934925079345703\n",
      "step = 4800, loss = 15.04626750946045\n",
      "step = 4900, loss = 20.641450881958008\n",
      "step = 5000, loss = 21.908058166503906\n",
      "step = 5100, loss = 18.734731674194336\n",
      "step = 5200, loss = 19.31891632080078\n",
      "step = 5300, loss = 25.264436721801758\n",
      "step = 5400, loss = 17.977319717407227\n",
      "step = 5500, loss = 16.535255432128906\n",
      "step = 5600, loss = 15.700976371765137\n",
      "step = 5700, loss = 20.001306533813477\n",
      "step = 5800, loss = 17.661113739013672\n",
      "step = 5900, loss = 14.911859512329102\n",
      "step = 6000, loss = 17.439786911010742\n",
      "step = 6100, loss = 15.188060760498047\n",
      "step = 6200, loss = 15.353245735168457\n",
      "step = 6300, loss = 23.465396881103516\n",
      "step = 6400, loss = 19.808767318725586\n",
      "step = 6500, loss = 12.431671142578125\n",
      "step = 6600, loss = 16.451852798461914\n",
      "step = 6700, loss = 13.502392768859863\n",
      "step = 6800, loss = 12.885601043701172\n",
      "step = 6900, loss = 16.57635498046875\n",
      "step = 7000, loss = 18.879499435424805\n",
      "step = 7100, loss = 15.584859848022461\n",
      "step = 7200, loss = 15.528554916381836\n",
      "step = 7300, loss = 10.970781326293945\n",
      "step = 7400, loss = 14.765509605407715\n",
      "step = 7500, loss = 13.644343376159668\n",
      "step = 7600, loss = 12.587804794311523\n",
      "step = 7700, loss = 12.566373825073242\n",
      "step = 7800, loss = 13.359224319458008\n",
      "step = 7900, loss = 14.741622924804688\n",
      "step = 8000, loss = 13.223092079162598\n",
      "step = 8100, loss = 11.566665649414062\n",
      "step = 8200, loss = 11.026261329650879\n",
      "step = 8300, loss = 13.092483520507812\n",
      "step = 8400, loss = 13.938937187194824\n",
      "step = 8500, loss = 12.351574897766113\n",
      "step = 8600, loss = 11.697808265686035\n",
      "step = 8700, loss = 13.1331787109375\n",
      "step = 8800, loss = 13.03372859954834\n",
      "step = 8900, loss = 11.440235137939453\n",
      "step = 9000, loss = 12.679542541503906\n",
      "step = 9100, loss = 15.088077545166016\n",
      "step = 9200, loss = 15.501200675964355\n",
      "step = 9300, loss = 10.443087577819824\n",
      "step = 9400, loss = 9.55126953125\n",
      "step = 9500, loss = 14.640449523925781\n",
      "step = 9600, loss = 10.026087760925293\n",
      "step = 9700, loss = 9.78222370147705\n",
      "step = 9800, loss = 10.69302749633789\n",
      "step = 9900, loss = 8.724312782287598\n",
      "train_accuracy=1.0\n",
      "test_accuracy=0.824999988079071\n"
     ]
    }
   ],
   "source": [
    "lossi = train(w1, b1, w2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAGdCAYAAAAMm0nCAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAPh1JREFUeJzt3Xl8VOXd///37NmYCQSSEAgSi8oiKovC1KW3mpuIsXet2LtYqrSi3tBgBVpAfrXU2y7wwFrFlVqteH8rVehDrUIFUxCoEkCjIIsgFjRonIQlyWSd9fz+iDkygkoWEg68no/HeZg512fOXOcyZN655jonNsMwDAEAAFiIvas7AAAA0FoEGAAAYDkEGAAAYDkEGAAAYDkEGAAAYDkEGAAAYDkEGAAAYDkEGAAAYDnOru7AiRKPx1VeXq5u3brJZrN1dXcAAMBxMAxDtbW1ysnJkd3+5fMsp2yAKS8vV25ubld3AwAAtMH+/fvVt2/fL20/ZQNMt27dJDUPgNfr7eLeAACA4xEMBpWbm2u+j3+ZUzbAtHxs5PV6CTAAAFjM1y3/YBEvAACwHAIMAACwHAIMAACwHAIMAACwHAIMAACwHAIMAACwHAIMAACwHAIMAACwHAIMAACwHAIMAACwHAIMAACwHAIMAACwHAJMK5VXN2rRun+rpiHS1V0BAOC01aoA079/f9lstqO2oqIiSVJTU5OKioqUkZGhtLQ0jRs3ThUVFQnHKCsrU2FhoVJSUpSZmamZM2cqGo0m1Kxdu1bDhw+Xx+PRgAEDtHjx4vadZQf6/uMlmv/KLv38b1u7uisAAJy2WhVg3nzzTX366afmVlxcLEn63ve+J0maPn26Xn75ZS1btkzr1q1TeXm5rrvuOvP5sVhMhYWFCofD2rBhg55++mktXrxYc+fONWv27dunwsJCXX755dqyZYumTZumW265RatWreqI8223/YcbJUnrdh/o4p4AAHD6shmGYbT1ydOmTdPy5cu1Z88eBYNB9erVS0uWLNH1118vSdq1a5cGDRqkkpISjR49Wq+88oquueYalZeXKysrS5K0aNEizZ49WwcOHJDb7dbs2bO1YsUKbd++3Xyd8ePHq7q6WitXrjzuvgWDQfl8PtXU1Mjr9bb1FI/S/84VkiS7Tdo7r7DDjgsAAI7//bvNa2DC4bD+8pe/6Oabb5bNZlNpaakikYjy8/PNmoEDB6pfv34qKSmRJJWUlGjo0KFmeJGkgoICBYNB7dixw6w58hgtNS3H+DKhUEjBYDBhO5HibY59AACgvdocYF588UVVV1frRz/6kSQpEAjI7XYrPT09oS4rK0uBQMCsOTK8tLS3tH1VTTAYVGNj45f2Z968efL5fOaWm5vb1lMDAAAnuTYHmCeffFJjx45VTk5OR/anzebMmaOamhpz279/f1d3CQAAnCDOtjzpo48+0j//+U89//zz5r7s7GyFw2FVV1cnzMJUVFQoOzvbrNm8eXPCsVquUjqy5otXLlVUVMjr9So5OflL++TxeOTxeNpyOgAAwGLaNAPz1FNPKTMzU4WFny9iHTFihFwul1avXm3u2717t8rKyuT3+yVJfr9f27ZtU2VlpVlTXFwsr9erwYMHmzVHHqOlpuUYAAAArQ4w8XhcTz31lCZOnCin8/MJHJ/Pp0mTJmnGjBl67bXXVFpaqh//+Mfy+/0aPXq0JGnMmDEaPHiwbrzxRm3dulWrVq3SXXfdpaKiInP2ZPLkydq7d69mzZqlXbt26dFHH9XSpUs1ffr0DjplAABgda3+COmf//ynysrKdPPNNx/Vdv/998tut2vcuHEKhUIqKCjQo48+arY7HA4tX75cU6ZMkd/vV2pqqiZOnKh77rnHrMnLy9OKFSs0ffp0LVy4UH379tUTTzyhgoKCNp4iAAA41bTrPjAnsxN9HxhJ+nA+94EBAKAjnfD7wAAAAHQVAgwAALAcAgwAALAcAgwAALAcAgwAALAcAgwAALAcAgwAALAcAgwAALAcAgwAALAcAgwAALAcAgwAALAcAgwAALAcAgwAALAcAgwAALAcAgwAALAcAgwAALAcAgwAALAcAgwAALAcAgwAALAcAgwAALAcAgwAALAcAgwAALAcAgwAALAcAgwAALAcAgwAALAcAgwAALAcAgwAALAcAgwAALAcAgwAALAcAgwAALAcAgwAALAcAgwAALAcAgwAALAcAgwAALAcAgwAALAcAgwAALCcVgeYTz75RD/84Q+VkZGh5ORkDR06VG+99ZbZbhiG5s6dq969eys5OVn5+fnas2dPwjEOHz6sCRMmyOv1Kj09XZMmTVJdXV1CzbvvvqtLL71USUlJys3N1YIFC9p4igAA4FTTqgBTVVWliy++WC6XS6+88op27typ++67T927dzdrFixYoAcffFCLFi3Spk2blJqaqoKCAjU1NZk1EyZM0I4dO1RcXKzly5dr/fr1uu2228z2YDCoMWPG6IwzzlBpaanuvfde3X333Xr88cc74JQBAIDV2QzDMI63+M4779Qbb7yhf/3rX8dsNwxDOTk5+tnPfqaf//znkqSamhplZWVp8eLFGj9+vN577z0NHjxYb775pkaOHClJWrlypa6++mp9/PHHysnJ0WOPPaZf/OIXCgQCcrvd5mu/+OKL2rVr13H1NRgMyufzqaamRl6v93hP8Wv1v3OF+fWH8ws77LgAAOD4379bNQPz0ksvaeTIkfre976nzMxMDRs2TH/605/M9n379ikQCCg/P9/c5/P5NGrUKJWUlEiSSkpKlJ6eboYXScrPz5fdbtemTZvMmssuu8wML5JUUFCg3bt3q6qq6ph9C4VCCgaDCRsAADg1tSrA7N27V4899pjOOussrVq1SlOmTNFPf/pTPf3005KkQCAgScrKykp4XlZWltkWCASUmZmZ0O50OtWjR4+EmmMd48jX+KJ58+bJ5/OZW25ubmtODQAAWEirAkw8Htfw4cP1u9/9TsOGDdNtt92mW2+9VYsWLTpR/Ttuc+bMUU1Njbnt37+/q7sEAABOkFYFmN69e2vw4MEJ+wYNGqSysjJJUnZ2tiSpoqIioaaiosJsy87OVmVlZUJ7NBrV4cOHE2qOdYwjX+OLPB6PvF5vwgYAAE5NrQowF198sXbv3p2w7/3339cZZ5whScrLy1N2drZWr15ttgeDQW3atEl+v1+S5Pf7VV1drdLSUrNmzZo1isfjGjVqlFmzfv16RSIRs6a4uFjnnHNOwhVPAADg9NSqADN9+nRt3LhRv/vd7/TBBx9oyZIlevzxx1VUVCRJstlsmjZtmn7zm9/opZde0rZt23TTTTcpJydH1157raTmGZurrrpKt956qzZv3qw33nhDU6dO1fjx45WTkyNJ+sEPfiC3261JkyZpx44deu6557Rw4ULNmDGjY88eAABYkrM1xRdeeKFeeOEFzZkzR/fcc4/y8vL0wAMPaMKECWbNrFmzVF9fr9tuu03V1dW65JJLtHLlSiUlJZk1zzzzjKZOnaorr7xSdrtd48aN04MPPmi2+3w+vfrqqyoqKtKIESPUs2dPzZ07N+FeMQAA4PTVqvvAWAn3gQEAwHpOyH1gAAAATgYEGAAAYDkEGAAAYDkEGAAAYDkEGAAAYDkEGAAAYDkEGAAAYDkEGAAAYDkEGAAAYDkEGAAAYDkEGAAAYDkEGAAAYDkEGAAAYDkEGAAAYDkEGAAAYDkEGAAAYDkEGAAAYDkEGAAAYDkEGAAAYDkEGAAAYDkEGAAAYDkEGAAAYDkEGAAAYDkEGAAAYDkEGAAAYDkEGAAAYDkEGAAAYDkEGAAAYDkEGAAAYDkEGAAAYDkEGAAAYDkEGAAAYDkEGAAAYDkEGAAAYDkEGAAAYDkEGAAAYDkEGAAAYDmtCjB33323bDZbwjZw4ECzvampSUVFRcrIyFBaWprGjRunioqKhGOUlZWpsLBQKSkpyszM1MyZMxWNRhNq1q5dq+HDh8vj8WjAgAFavHhx288QAACcclo9AzNkyBB9+umn5vb666+bbdOnT9fLL7+sZcuWad26dSovL9d1111ntsdiMRUWFiocDmvDhg16+umntXjxYs2dO9es2bdvnwoLC3X55Zdry5YtmjZtmm655RatWrWqnacKAABOFc5WP8HpVHZ29lH7a2pq9OSTT2rJkiW64oorJElPPfWUBg0apI0bN2r06NF69dVXtXPnTv3zn/9UVlaWLrjgAv3617/W7Nmzdffdd8vtdmvRokXKy8vTfffdJ0kaNGiQXn/9dd1///0qKCho5+kCAIBTQatnYPbs2aOcnBydeeaZmjBhgsrKyiRJpaWlikQiys/PN2sHDhyofv36qaSkRJJUUlKioUOHKisry6wpKChQMBjUjh07zJojj9FS03KMLxMKhRQMBhM2AABwampVgBk1apQWL16slStX6rHHHtO+fft06aWXqra2VoFAQG63W+np6QnPycrKUiAQkCQFAoGE8NLS3tL2VTXBYFCNjY1f2rd58+bJ5/OZW25ubmtODQAAWEirPkIaO3as+fV5552nUaNG6YwzztDSpUuVnJzc4Z1rjTlz5mjGjBnm42AwSIgBAOAU1a7LqNPT03X22Wfrgw8+UHZ2tsLhsKqrqxNqKioqzDUz2dnZR12V1PL462q8Xu9XhiSPxyOv15uwAQCAU1O7AkxdXZ3+/e9/q3fv3hoxYoRcLpdWr15ttu/evVtlZWXy+/2SJL/fr23btqmystKsKS4ultfr1eDBg82aI4/RUtNyDAAAgFYFmJ///Odat26dPvzwQ23YsEHf/e535XA4dMMNN8jn82nSpEmaMWOGXnvtNZWWlurHP/6x/H6/Ro8eLUkaM2aMBg8erBtvvFFbt27VqlWrdNddd6moqEgej0eSNHnyZO3du1ezZs3Srl279Oijj2rp0qWaPn16x589AACwpFatgfn44491ww036NChQ+rVq5cuueQSbdy4Ub169ZIk3X///bLb7Ro3bpxCoZAKCgr06KOPms93OBxavny5pkyZIr/fr9TUVE2cOFH33HOPWZOXl6cVK1Zo+vTpWrhwofr27asnnniCS6gBAIDJZhiG0dWdOBGCwaB8Pp9qamo6dD1M/ztXmF9/OL+ww44LAACO//2bv4UEAAAshwADAAAshwADAAAshwADAAAshwADAAAshwADAAAshwADAAAshwADAAAshwADAAAshwADAAAshwADAAAshwADAAAshwADAAAshwADAAAshwDTDoZhdHUXAAA4LRFgAACA5RBg2oEJGAAAugYBBgAAWA4Bph2YgAEAoGsQYAAAgOUQYNqBq5AAAOgaBBgAAGA5BJh2YP4FAICuQYABAACWQ4BpB5bAAADQNQgwAADAcggw7WCwCgYAgC5BgAEAAJZDgGkH1sAAANA1CDAAAMByCDAAAMByCDAAAMByCDDtwBoYAAC6BgEGAABYDgGmHbgPDAAAXYMAAwAALKddAWb+/Pmy2WyaNm2aua+pqUlFRUXKyMhQWlqaxo0bp4qKioTnlZWVqbCwUCkpKcrMzNTMmTMVjUYTatauXavhw4fL4/FowIABWrx4cXu6ekKwBgYAgK7R5gDz5ptv6o9//KPOO++8hP3Tp0/Xyy+/rGXLlmndunUqLy/XddddZ7bHYjEVFhYqHA5rw4YNevrpp7V48WLNnTvXrNm3b58KCwt1+eWXa8uWLZo2bZpuueUWrVq1qq3dBQAAp5A2BZi6ujpNmDBBf/rTn9S9e3dzf01NjZ588kn94Q9/0BVXXKERI0boqaee0oYNG7Rx40ZJ0quvvqqdO3fqL3/5iy644AKNHTtWv/71r/XII48oHA5LkhYtWqS8vDzdd999GjRokKZOnarrr79e999/fweccsdhAgYAgK7RpgBTVFSkwsJC5efnJ+wvLS1VJBJJ2D9w4ED169dPJSUlkqSSkhINHTpUWVlZZk1BQYGCwaB27Nhh1nzx2AUFBeYxAADA6c3Z2ic8++yzevvtt/Xmm28e1RYIBOR2u5Wenp6wPysrS4FAwKw5Mry0tLe0fVVNMBhUY2OjkpOTj3rtUCikUChkPg4Gg609tVYzWAQDAECXaNUMzP79+3XHHXfomWeeUVJS0onqU5vMmzdPPp/P3HJzc7u6SwAA4ARpVYApLS1VZWWlhg8fLqfTKafTqXXr1unBBx+U0+lUVlaWwuGwqqurE55XUVGh7OxsSVJ2dvZRVyW1PP66Gq/Xe8zZF0maM2eOampqzG3//v2tObU2Yf4FAICu0aoAc+WVV2rbtm3asmWLuY0cOVITJkwwv3a5XFq9erX5nN27d6usrEx+v1+S5Pf7tW3bNlVWVpo1xcXF8nq9Gjx4sFlz5DFaalqOcSwej0derzdhAwAAp6ZWrYHp1q2bzj333IR9qampysjIMPdPmjRJM2bMUI8ePeT1enX77bfL7/dr9OjRkqQxY8Zo8ODBuvHGG7VgwQIFAgHdddddKioqksfjkSRNnjxZDz/8sGbNmqWbb75Za9as0dKlS7VixYqOOGcAAGBxrV7E+3Xuv/9+2e12jRs3TqFQSAUFBXr00UfNdofDoeXLl2vKlCny+/1KTU3VxIkTdc8995g1eXl5WrFihaZPn66FCxeqb9++euKJJ1RQUNDR3W0X1vACANA1bMYpeilNMBiUz+dTTU1Nh36c1P/Oz2eBtv5qjHzJrg47NgAAp7vjff/mbyG1xykZ/QAAOPkRYAAAgOUQYNrBYAoGAIAuQYABAACWQ4Bph1Nz+TMAACc/AgwAALAcAkw7MAEDAEDXIMAAAADLIcC0wyl6D0AAAE56BBgAAGA5BJh2YP4FAICuQYABAACWQ4BpB5bAAADQNQgwAADAcggw7cDfQgIAoGsQYAAAgOUQYNqDCRgAALoEAQYAAFgOAaYdmIABAKBrEGAAAIDlEGDagfvAAADQNQgw7fB2WVVXdwEAgNMSAaYdfvLM213dBQAATksEGAAAYDkEGAAAYDkEGAAAYDkEGAAAYDkEGAAAYDkEGAAAYDkEGAAAYDkEGAAAYDkEGAAAYDkEGAAAYDkEGAAAYDkEGAAAYDkEmFZyOxgyAAC6Gu/GrTRmSFZXdwEAgNNeqwLMY489pvPOO09er1der1d+v1+vvPKK2d7U1KSioiJlZGQoLS1N48aNU0VFRcIxysrKVFhYqJSUFGVmZmrmzJmKRqMJNWvXrtXw4cPl8Xg0YMAALV68uO1n2MHsNltXdwEAgNNeqwJM3759NX/+fJWWluqtt97SFVdcoe985zvasWOHJGn69Ol6+eWXtWzZMq1bt07l5eW67rrrzOfHYjEVFhYqHA5rw4YNevrpp7V48WLNnTvXrNm3b58KCwt1+eWXa8uWLZo2bZpuueUWrVq1qoNOGQAAWJ3NMAyjPQfo0aOH7r33Xl1//fXq1auXlixZouuvv16StGvXLg0aNEglJSUaPXq0XnnlFV1zzTUqLy9XVlbzRzGLFi3S7NmzdeDAAbndbs2ePVsrVqzQ9u3bzdcYP368qqurtXLlyuPuVzAYlM/nU01Njbxeb3tOMcFP//qOXtpabj7+cH5hhx0bAIDT3fG+f7d5DUwsFtOzzz6r+vp6+f1+lZaWKhKJKD8/36wZOHCg+vXrp5KSEklSSUmJhg4daoYXSSooKFAwGDRncUpKShKO0VLTcowvEwqFFAwGE7YTYdyIvifkuAAA4Pi1OsBs27ZNaWlp8ng8mjx5sl544QUNHjxYgUBAbrdb6enpCfVZWVkKBAKSpEAgkBBeWtpb2r6qJhgMqrGx8Uv7NW/ePPl8PnPLzc1t7akdl2+d3euEHBcAABy/VgeYc845R1u2bNGmTZs0ZcoUTZw4UTt37jwRfWuVOXPmqKamxtz279/f1V0CAAAniLO1T3C73RowYIAkacSIEXrzzTe1cOFCff/731c4HFZ1dXXCLExFRYWys7MlSdnZ2dq8eXPC8VquUjqy5otXLlVUVMjr9So5OflL++XxeOTxeFp7OgAAwILafR+YeDyuUCikESNGyOVyafXq1Wbb7t27VVZWJr/fL0ny+/3atm2bKisrzZri4mJ5vV4NHjzYrDnyGC01LccAAABo1QzMnDlzNHbsWPXr10+1tbVasmSJ1q5dq1WrVsnn82nSpEmaMWOGevToIa/Xq9tvv11+v1+jR4+WJI0ZM0aDBw/WjTfeqAULFigQCOiuu+5SUVGROXsyefJkPfzww5o1a5ZuvvlmrVmzRkuXLtWKFSs6/uwBAIAltSrAVFZW6qabbtKnn34qn8+n8847T6tWrdJ//ud/SpLuv/9+2e12jRs3TqFQSAUFBXr00UfN5zscDi1fvlxTpkyR3+9XamqqJk6cqHvuucesycvL04oVKzR9+nQtXLhQffv21RNPPKGCgoIOOmUAAGB17b4PzMnqRN0HRpL63/n5bBD3gQEAoOOc8PvAAAAAdBUCDAAAsBwCDAAAsBwCDAAAsBwCDAAAsBwCDAAAsBwCDAAAsBwCDAAAsBwCDAAAsBwCDAAAsBwCDAAAsBwCDAAAsBwCDAAAsBwCDAAAsBwCDAAAsBwCDAAAsBwCDAAAsBwCDAAAsBwCDAAAsBwCDAAAsBwCDAAAsBwCDAAAsBwCDAAAsBwCDAAAsBwCDAAAsBwCDAAAsBwCDAAAsBwCDAAAsBwCDAAAsBwCDAAAsBwCDAAAsBwCDAAAsBwCDAAAsBwCDAAAsBwCDAAAsBwCDAAAsJxWBZh58+bpwgsvVLdu3ZSZmalrr71Wu3fvTqhpampSUVGRMjIylJaWpnHjxqmioiKhpqysTIWFhUpJSVFmZqZmzpypaDSaULN27VoNHz5cHo9HAwYM0OLFi9t2hgAA4JTTqgCzbt06FRUVaePGjSouLlYkEtGYMWNUX19v1kyfPl0vv/yyli1bpnXr1qm8vFzXXXed2R6LxVRYWKhwOKwNGzbo6aef1uLFizV37lyzZt++fSosLNTll1+uLVu2aNq0abrlllu0atWqDjhlAABgdTbDMIy2PvnAgQPKzMzUunXrdNlll6mmpka9evXSkiVLdP3110uSdu3apUGDBqmkpESjR4/WK6+8omuuuUbl5eXKysqSJC1atEizZ8/WgQMH5Ha7NXv2bK1YsULbt283X2v8+PGqrq7WypUrj6tvwWBQPp9PNTU18nq9bT3FY+p/5wrz6w/nF3bosQEAOJ0d7/t3u9bA1NTUSJJ69OghSSotLVUkElF+fr5ZM3DgQPXr108lJSWSpJKSEg0dOtQML5JUUFCgYDCoHTt2mDVHHqOlpuUYAADg9OZs6xPj8bimTZumiy++WOeee64kKRAIyO12Kz09PaE2KytLgUDArDkyvLS0t7R9VU0wGFRjY6OSk5OP6k8oFFIoFDIfB4PBtp4aAAA4ybV5BqaoqEjbt2/Xs88+25H9abN58+bJ5/OZW25ubld3CQAAnCBtCjBTp07V8uXL9dprr6lv377m/uzsbIXDYVVXVyfUV1RUKDs726z54lVJLY+/rsbr9R5z9kWS5syZo5qaGnPbv39/W04NAABYQKsCjGEYmjp1ql544QWtWbNGeXl5Ce0jRoyQy+XS6tWrzX27d+9WWVmZ/H6/JMnv92vbtm2qrKw0a4qLi+X1ejV48GCz5shjtNS0HONYPB6PvF5vwgYAAE5NrVoDU1RUpCVLlujvf/+7unXrZq5Z8fl8Sk5Ols/n06RJkzRjxgz16NFDXq9Xt99+u/x+v0aPHi1JGjNmjAYPHqwbb7xRCxYsUCAQ0F133aWioiJ5PB5J0uTJk/Xwww9r1qxZuvnmm7VmzRotXbpUK1as+NK+dRXDMGSz2bq6GwAAnFZaNQPz2GOPqaamRv/xH/+h3r17m9tzzz1n1tx///265pprNG7cOF122WXKzs7W888/b7Y7HA4tX75cDodDfr9fP/zhD3XTTTfpnnvuMWvy8vK0YsUKFRcX6/zzz9d9992nJ554QgUFBR1wygAAwOradR+Yk9mJvA9M0ZK3teLdTyVJe393tex2ZmAAAOgInXIfmNMVcQUAgK5FgGkD1rwAANC1CDDtdEp+/gYAwEmOAAMAACyHANNOp+gaaAAATmoEmDZgBQwAAF2LAAMAACyHANNOfIAEAEDnI8AAAADLIcC0AbeBAQCgaxFg2omLkAAA6HwEGAAAYDkEmDY48hMkg2W8AAB0OgIMAACwHAIMAACwHAJMGxz516hZxAsAQOcjwLQBV1EDANC1CDAAAMByCDAAAMByCDAAAMByCDBtccQiGBbxAgDQ+QgwAADAcggw7cSdeAEA6HwEGAAAYDkEmDawcScYAAC6FAGmnVjECwBA5yPAAAAAyyHAtMGh+lBXdwEAgNMaAaYN1u4+YH7NJ0gAAHQ+AgwAALAcAkw7GaziBQCg0xFgAACA5RBgAACA5RBg2okPkAAA6HwEGAAAYDkEmDa49dI882vW8AIA0PkIMG2Q4naaX1cGm7qwJwAAnJ5aHWDWr1+vb3/728rJyZHNZtOLL76Y0G4YhubOnavevXsrOTlZ+fn52rNnT0LN4cOHNWHCBHm9XqWnp2vSpEmqq6tLqHn33Xd16aWXKikpSbm5uVqwYEHrz+4EsR3xtxyPvKkdAADoHK0OMPX19Tr//PP1yCOPHLN9wYIFevDBB7Vo0SJt2rRJqampKigoUFPT5zMVEyZM0I4dO1RcXKzly5dr/fr1uu2228z2YDCoMWPG6IwzzlBpaanuvfde3X333Xr88cfbcIod78i/Rh3jMyQAADqd8+tLEo0dO1Zjx449ZpthGHrggQd011136Tvf+Y4k6f/+7/+UlZWlF198UePHj9d7772nlStX6s0339TIkSMlSQ899JCuvvpq/f73v1dOTo6eeeYZhcNh/fnPf5bb7daQIUO0ZcsW/eEPf0gIOl3lyBmYWJwAAwBAZ+vQNTD79u1TIBBQfn6+uc/n82nUqFEqKSmRJJWUlCg9Pd0ML5KUn58vu92uTZs2mTWXXXaZ3G63WVNQUKDdu3erqqrqmK8dCoUUDAYTts5AgAEAoPN1aIAJBAKSpKysrIT9WVlZZlsgEFBmZmZCu9PpVI8ePRJqjnWMI1/ji+bNmyefz2duubm57T+hL3HEBAwBBgCALnDKXIU0Z84c1dTUmNv+/ftP2Gsd+RESfwsJAIDO16EBJjs7W5JUUVGRsL+iosJsy87OVmVlZUJ7NBrV4cOHE2qOdYwjX+OLPB6PvF5vwnai2I5IMFFmYAAA6HQdGmDy8vKUnZ2t1atXm/uCwaA2bdokv98vSfL7/aqurlZpaalZs2bNGsXjcY0aNcqsWb9+vSKRiFlTXFysc845R927d+/ILrfJkbMuxBcAADpfqwNMXV2dtmzZoi1btkhqXri7ZcsWlZWVyWazadq0afrNb36jl156Sdu2bdNNN92knJwcXXvttZKkQYMG6aqrrtKtt96qzZs364033tDUqVM1fvx45eTkSJJ+8IMfyO12a9KkSdqxY4eee+45LVy4UDNmzOiwE2+PSOzz2BLnIyQAADpdqy+jfuutt3T55Zebj1tCxcSJE7V48WLNmjVL9fX1uu2221RdXa1LLrlEK1euVFJSkvmcZ555RlOnTtWVV14pu92ucePG6cEHHzTbfT6fXn31VRUVFWnEiBHq2bOn5s6de1JcQi1J5/X1mV+TXwAA6Hw24xRdhRoMBuXz+VRTU9Ph62HicUNn/n//kCTdckme7rpmcIceHwCA09Xxvn+fMlchdaYjr0JiDS8AAJ2PANMGR16FxBoYAAA6HwEGAABYDgGmnZiBAQCg8xFg2okAAwBA5yPAtBOLeAEA6HwEmHY6Ra9CBwDgpEaAaad4vKt7AADA6YcA006sgQEAoPMRYNopEmMKBgCAzkaAaaemCAEGAIDORoBppyiLYAAA6HQEmHaKxFgDAwBAZyPAtFO2N6mruwAAwGmHANNG/3V+jiQp1ePs4p4AAHD6IcC0Uf+eqZK4CgkAgK5AgGkjl90miUW8AAB0BQJMG7mczUMXjrKIFwCAzkaAaaOkzwJMYyTaxT0BAOD0Q4Bpo+6pbklSVX2ki3sCAMDphwDTRj0+CzAlew/xF6kBAOhkBJg2agkwkrR+z8Eu7AkAAKcfAkwbHRlg/rmzogt7AgDA6YcA00ZHBpj0FFcX9gQAgNMPAaaNPE6HBmSmSZKSXI4u7g0AAKcXAkw7XDkoU5J076rdWvf+gS7uDQAApw8CTDv0SvOYX0/882a9/tli3oN1IX1QWddV3QIA4JRHgGmHXt08CY9/+OQmSdLNi99U/h/WafsnNV3RLQAATnkEmHbok5581L7n3/5Y737cHFze+IDLqwEAOBEIMO0wrF93DeuXnrBvxtKt5tfRODe4AwDgRCDAtIPDbtMLP7lY864besz2SCyupW/t18rtnybsDzZFuHsvAADtYDNO0XfSYDAon8+nmpoaeb3eE/56jeGYfvHCNj3/zifHbP/rraP13qdBjT4zQ//18Ov67wtz9bvvHjv4AABwujre928CTAd7fc9BczHv1/lwfqFqGiJyO+1KdnMvGQAAjvf9m4+QOtglZ/XUW3fl66zPbnL3Vf6154AuXbBGg+au1I1PblJ1Q1jRWDyh5vU9B/XRofqjnlvTEFHkC7UAAJwumIE5wSqCTfrJM2+r9KOq46pPT3Fp7Lm9dePoM1TdGNYP/rRJuT2Stfbnl8tht0mS9h9u0KULXpMv2aUtc/9TNlvzfsMwzK9bHq/fc1BnZaYp54grpl7fc1BnZ6Up05vUgWcKAED78RHSSRJgWhiGodpQVEs2lWn+K7u+tt5pt8nttKshHDP3Dert1VM/ulC/XrFTK95tXhj8/yZdpPP6pOv2Z9/Rxn8f0oM3DNNV52YrHjf0t7c/1qy/vauB2d20ctplkqR17x/QxD9v1pk9U7Xm5/8hwzBUWRtSFmEGAHASIMCcZAHmi/YeqNNdL25Xti9Jfbun6MHVe47reT1S3TpcH/7Kmgmj+mnVjoAO1n1eN7PgHE3+1jd0x7PvaPln4efX3xmijXsPa8W2T3Xd8D7K8iapeGeFhuR4dd/3zldVQ0R/2fiRrjmvt3qnJ8tpt8lus8nlsCXM9JQdapAv2SVfikvxuCGbTQntdaGo3v6oShcP6GnOIjWGYzrcED7qXjpfnEUCAJxeTokA88gjj+jee+9VIBDQ+eefr4ceekgXXXTRcT33ZA8wX7T6vQpVN0RUeF5vfVLdqDXvVeqDyjpdmNdD//vyDtU2RRPqC4ZkqbYpqg3/PnTcr3F+bro+qKhV/RGzOl/Gm+RU8Auv2aJv92Tl+JKVkeZWj1S3lmwuk03SRXk9tLM8qLgh9Uxz66K8Hroj/2zNfXG7Vu+q1NVDszX6zAzVh2JaVrpfew/U65rzeivZ5dAVAzO1ad9hFe+s0A0X5WrrxzU6UBuSL9mlmQXn6OysbrLbpP8r+UgfHKhTOBrXf5zTS7VNUWX7knRh/x6KROP68FC9zuyVJl+ySxs+OKi3y6p0bh+fvnV2L9lsNhmGoX8fqJPb4VD3VJcaIzEdrg/r3f01umpotjxOuzzOzxdUx+OG6sNRdUty6b1Pg0pPcam37+gbGB6pMtikUDSu3B4pCfsP1YXUFI0f8waIAIBmlg8wzz33nG666SYtWrRIo0aN0gMPPKBly5Zp9+7dyszM/NrnWy3AfJWmSHPg+LiqUevfP6Bz+/h0Yf/uihvSO2VVSktyypvk0t4D9XrqjX1KT3GrIRxVksuhTK9Hmd2SdO+qXWqKnLqLfh12m+KGoZbv5hxfksprmsz24f3SdWavNG3dX609X/F3qtwOu8YMydL2T2pUF2oOcFUNEQ3t49OW/dWSmv+ExDlZ3dS3e7JKP6rS/qoGZXuTdMlZPbXtk6C2flY3ZnCWxgxp/jivvKZRT/5rn2pDUfXq5lFeRqouzOuul7d+quqGsFLcTl11braG5HhVvLNCGWkeuR027a6o1Te/0VM7ymv0cVWjhvfrrgO1IQ3ITNPFA3rq46oGfXCgTvsO1Ku3L0mXD8xUJGZo/+EGLSv9WJFYXBO/2V8jz+gul8OuhnBUa3ZV6vm3P9Hwz27COLJ/Dw3ITNM7ZdUqO9wgqTmkfuvs5oC4p7JWQ3K86pnm0ZJNZeqW5NTI/j20cntA3mSX/nNQlmqbIiqvaVJez1SluB2qbojIbpOcDrvqQlENyExTfSiqtz6s0geVdRrYu5suyE1XRbBJjeGY+nRPVigaVzRm6Ly+Pnmcdr3+wUHtPVCvS8/qqbpQVHsP1GtAZpq6JTlV0xhR9xS30lNc+uhQgxrCMbmddnmcdrmddrkdzdcn9Eh1y+Ww64PKOu0or5Eh6cyeqcr2JSkj1SOXw6aGSEyhSFypHoeSXQ4dqg/ro0MN6pnmVrav+aPVcDSucDSu6saIqhvC8ia51L9nqlwOu5oiMQVqmtQ7PUk1jRGVflils7O76cyeqZKkg3VhhaIxeZNd6uZxHjXDGI8bqmmMyOGwHdVeVR/Wtk9qdHZWN7MvVfXh5lDtcalbklN2e+K6t2BjVOFYXMnu5vNx2BNnQyuCTUpPdqlHqvuYs51fnAWNxQ3zGMGmiBw2m1LcjuOeKY3G4jIkuRxcM4LjY/kAM2rUKF144YV6+OGHJUnxeFy5ubm6/fbbdeedd37t80+lANMRAjVNKt4ZUH04pqvP7a0+3ZMVicW1ed9hDe3jU3VjRD1S3JJNstuk3YFaBYJN6p+Rqo+rGjSot1fJLoeCTRG9XVatUCSmnZ8GFahp0ogzuuuSs3pp+dZyHaoP6/oRfRWJxfXY2n9r077DkqQkl10uu129vB71TPWob/dkZXqT9NquStWHo/q4qvGoPmd7k1QXiqo+HNWR36VuZ/MPQqfdpm/0SlNNY8R84/Ulu1TTGDFrz+3j1Z6KOoWin4c3h90mu02KxE7Kb/3Tnsthk9thP66ZwuNhs0nH+1POabcd9x203U67fMkuHaoLKW40/7s58qndPE7FDCNhHZvbYVeSq/n7t6W2MRJT7LMHniPClyTVHfG937d7supDUVU1fP797bTb1DPNo/QUl4KNER2sCyv8hasTW17T43LoYF3IPJ7baVevNI/CsbhicUPJn7WHonGluh1K9TjVFIkp2BRVn/RkReNxVQRD5jF9Kc0BKhSJqykSk9NhU7LLoSSXQ2me5mAVqGnSJ9WNisUNOe2ftX8WrL74UXTL+bSEJbvNJptNzcePxtT02Tilp7jVPcWlpkhch+vDaghHldsjRSluhxrDMdWHY4obhuw2m8LRuOKGIV9yc19t+vz1HHabYnFDjZHmY4eicUVicbkdzSHY6bApFpccdinF5ZTHZZdhSIYMxeNq/oVJzYEvbiT+15DMX6icdpviRnMI9qW45Et2yabm78uWc4zGDEVicUXjhtn3UDRu/r/wJrl0uCGsjw83KBo31CPVrYw0t9wO+2d9kNmXFtFY8+xxXSgqt8Ou3r4kpXqcisWbX+twfViVtSE1hmPKSHMrI9WjjDR38/dkOKaGcEwN4aiaIs1hOMvrUUaaR47PxrUuFFVtKKqfXjFAI/v3+Np/L61h6QATDoeVkpKiv/3tb7r22mvN/RMnTlR1dbX+/ve/H/WcUCikUChkPg4Gg8rNzSXAdCHDMPRJdXMw6ds95StrP6isVX0opvP6+hRsjMqX4jLbwtG4+UPGm+Qy75nT8puiYRjaf7hRSS67Mr1JOlAb0qZ9h9QnPVnD+nXX/sMN+ud7FapriqpP92RdMTBTbqddB2vDihmG9h2s0yUDeqm6Mayd5UG9urNCOb4kDe/XXdHP/rG//sFBXXZ2L53Xx6fy6iZt3HtIB+tDGpbbXQMyU/V2WbX2VNTqrMxu+tY5vVTVENYzG8u092Cd3A67uiW5NLSPT0P6eFURbNKuQK0+OtigiwdkaGT/HvroUIOe2fSRqhsiGtYvXaFIXA2RmHqmubX9kxpleZM0qLdXB2pD8ia79E5ZlT461KDeviQNzO6mvt1TtL28RjvKg0p2OZSR5taovAxFYnGt2hFQRbBJkVjzm1SW16OhfX2KRA0luex666MqVdWHNbSvTwOzvbLZpC37q7Vp72F1T3HpG5lpevujKtWHYzorM02GpI+rGjTijO6yyaYd5TXyJruU7U3SB5V1stmag6RhSJF4XC6HXfsO1svjtOuC3HQNyEzTWx9W6ZOqRmV6PUpxO1Ve3SiXw674Z4vKJSnF7VCWN0kfHqpXN49TAzLTtKeiTtG4ofQUlw7WhRSJGcpIdcuX4lL4sx/4oUhM4VhchiEzuHZLcmpIjlc22bS/qkGVtSGFo18+I9knPVmH6kNHzVp2S3IqPcWlqvqIOUMnNb+htwSHPunJOlAbMh/bbM2zD1/1el8l25ukitqmo0J8W4+X5nEm9B1oj4XjL9B3LujToce0dIApLy9Xnz59tGHDBvn9fnP/rFmztG7dOm3adPSN4u6++2797//+71H7CTBA+xmGoWjcaPPHAE2RmFwOe8LHGV/2OuU1zR8r9euRIrfTrmgsLofdZobVlt/aI7HmwJLmcX7p8YJNEYUicfVMcx91i4H6cEyRaPNvl26HXQ2RmGqbInI57OqZ5jE/jrHbmwPIkf2Pxw3tr2ow12BlpLpVXtMkl8OmzG5JaorE9HFVg2w2m3K7N59HUySmQ/Vh8yNhh80mQ82zkxmpHkXjcR2qC5szQDZJSS6Hsn1JqqoP6/2KWnmTXTojI0UpbqfC0ZbfoptU1RCRN8mpXt086pnmkcdpVygaV2M4psbIZ1s4pixvknp18ygcjauytkkHakNyO5vPqyEcU680jzwuuxrDMdU2Rc1Zpo8ONchht+mc7Oa1aFUNzR+l1TU1f1TtcdkVjRlqijT/5l4fiioaNz67SCFZKS5nQj+aorGjAphhSNF43JyZisWbQ2iSy9E8g+Rs/jisqiGs6oaIklx2pae4lexy6KNDDQrH4kpxOZTicchha571cDvtstma75v1xdAWixuyfzYrlPzZazjsNkVihkLRmKJxQw6bTTHDUGM4plA0JptsCTMndlvzbK7U/N8j97d8u0VjzR/BOR02Ha4Pqz4UkyEjYdbEaW+e8XE7mvsbixvyOB1yO+2qbYqoPhSVL8WtPunJ8jjtOlQfVlV92LwXmM1mM2d1Wl7XYbcrzeNQqtuppmhcn1Y3qjESk9Nuk9NhV/cUl3p1a/4F4nB9WAfrQjpQG5LdZmv+ONXtVKq7eUattimqytomHa4PK240zxSmeZxK8zh1UV6Po9b7tddpF2CYgQEAwPqON8B8+a8uXahnz55yOByqqKhI2F9RUaHs7OxjPsfj8cjj8XRG9wAAQBc7KZeFu91ujRgxQqtXrzb3xeNxrV69OmFGBgAAnJ5OyhkYSZoxY4YmTpyokSNH6qKLLtIDDzyg+vp6/fjHP+7qrgEAgC520gaY73//+zpw4IDmzp2rQCCgCy64QCtXrlRWVlZXdw0AAHSxk3IRb0fgPjAAAFjP8b5/n5RrYAAAAL4KAQYAAFgOAQYAAFgOAQYAAFgOAQYAAFgOAQYAAFgOAQYAAFgOAQYAAFjOSXsn3vZquT9fMBjs4p4AAIDj1fK+/XX32T1lA0xtba0kKTc3t4t7AgAAWqu2tlY+n+9L20/ZPyUQj8dVXl6ubt26yWazddhxg8GgcnNztX//fv5EwQnGWHcOxrlzMM6dg3HuHCdynA3DUG1trXJycmS3f/lKl1N2BsZut6tv374n7Pher5d/HJ2Ese4cjHPnYJw7B+PcOU7UOH/VzEsLFvECAADLIcAAAADLIcC0ksfj0a9+9St5PJ6u7sopj7HuHIxz52CcOwfj3DlOhnE+ZRfxAgCAUxczMAAAwHIIMAAAwHIIMAAAwHIIMAAAwHIIMK30yCOPqH///kpKStKoUaO0efPmru7SSWvevHm68MIL1a1bN2VmZuraa6/V7t27E2qamppUVFSkjIwMpaWlady4caqoqEioKSsrU2FhoVJSUpSZmamZM2cqGo0m1Kxdu1bDhw+Xx+PRgAEDtHjx4hN9eiet+fPny2azadq0aeY+xrljfPLJJ/rhD3+ojIwMJScna+jQoXrrrbfMdsMwNHfuXPXu3VvJycnKz8/Xnj17Eo5x+PBhTZgwQV6vV+np6Zo0aZLq6uoSat59911deumlSkpKUm5urhYsWNAp53eyiMVi+uUvf6m8vDwlJyfrG9/4hn79618n/G0cxrr11q9fr29/+9vKycmRzWbTiy++mNDemWO6bNkyDRw4UElJSRo6dKj+8Y9/tP6EDBy3Z5991nC73caf//xnY8eOHcatt95qpKenGxUVFV3dtZNSQUGB8dRTTxnbt283tmzZYlx99dVGv379jLq6OrNm8uTJRm5urrF69WrjrbfeMkaPHm1885vfNNuj0ahx7rnnGvn5+cY777xj/OMf/zB69uxpzJkzx6zZu3evkZKSYsyYMcPYuXOn8dBDDxkOh8NYuXJlp57vyWDz5s1G//79jfPOO8+44447zP2Mc/sdPnzYOOOMM4wf/ehHxqZNm4y9e/caq1atMj744AOzZv78+YbP5zNefPFFY+vWrcZ//dd/GXl5eUZjY6NZc9VVVxnnn3++sXHjRuNf//qXMWDAAOOGG24w22tqaoysrCxjwoQJxvbt242//vWvRnJysvHHP/6xU8+3K/32t781MjIyjOXLlxv79u0zli1bZqSlpRkLFy40axjr1vvHP/5h/OIXvzCef/55Q5LxwgsvJLR31pi+8cYbhsPhMBYsWGDs3LnTuOuuuwyXy2Vs27atVedDgGmFiy66yCgqKjIfx2IxIycnx5g3b14X9so6KisrDUnGunXrDMMwjOrqasPlchnLli0za9577z1DklFSUmIYRvM/OLvdbgQCAbPmscceM7xerxEKhQzDMIxZs2YZQ4YMSXit73//+0ZBQcGJPqWTSm1trXHWWWcZxcXFxre+9S0zwDDOHWP27NnGJZdc8qXt8XjcyM7ONu69915zX3V1teHxeIy//vWvhmEYxs6dOw1JxptvvmnWvPLKK4bNZjM++eQTwzAM49FHHzW6d+9ujnvLa59zzjkdfUonrcLCQuPmm29O2HfdddcZEyZMMAyDse4IXwwwnTmm//3f/20UFhYm9GfUqFHG//zP/7TqHPgI6TiFw2GVlpYqPz/f3Ge325Wfn6+SkpIu7Jl11NTUSJJ69OghSSotLVUkEkkY04EDB6pfv37mmJaUlGjo0KHKysoyawoKChQMBrVjxw6z5shjtNScbv9fioqKVFhYeNRYMM4d46WXXtLIkSP1ve99T5mZmRo2bJj+9Kc/me379u1TIBBIGCOfz6dRo0YljHN6erpGjhxp1uTn58tut2vTpk1mzWWXXSa3223WFBQUaPfu3aqqqjrRp3lS+OY3v6nVq1fr/ffflyRt3bpVr7/+usaOHSuJsT4ROnNMO+pnCQHmOB08eFCxWCzhB7wkZWVlKRAIdFGvrCMej2vatGm6+OKLde6550qSAoGA3G630tPTE2qPHNNAIHDMMW9p+6qaYDCoxsbGE3E6J51nn31Wb7/9tubNm3dUG+PcMfbu3avHHntMZ511llatWqUpU6bopz/9qZ5++mlJn4/TV/2MCAQCyszMTGh3Op3q0aNHq/5fnOruvPNOjR8/XgMHDpTL5dKwYcM0bdo0TZgwQRJjfSJ05ph+WU1rx/yU/WvUOLkUFRVp+/btev3117u6K6ec/fv364477lBxcbGSkpK6ujunrHg8rpEjR+p3v/udJGnYsGHavn27Fi1apIkTJ3Zx704tS5cu1TPPPKMlS5ZoyJAh2rJli6ZNm6acnBzGGiZmYI5Tz5495XA4jrpyo6KiQtnZ2V3UK2uYOnWqli9frtdee019+/Y192dnZyscDqu6ujqh/sgxzc7OPuaYt7R9VY3X61VycnJHn85Jp7S0VJWVlRo+fLicTqecTqfWrVunBx98UE6nU1lZWYxzB+jdu7cGDx6csG/QoEEqKyuT9Pk4fdXPiOzsbFVWVia0R6NRHT58uFX/L051M2fONGdhhg4dqhtvvFHTp083ZxgZ647XmWP6ZTWtHXMCzHFyu90aMWKEVq9ebe6Lx+NavXq1/H5/F/bs5GUYhqZOnaoXXnhBa9asUV5eXkL7iBEj5HK5EsZ09+7dKisrM8fU7/dr27ZtCf9oiouL5fV6zTcTv9+fcIyWmtPl/8uVV16pbdu2acuWLeY2cuRITZgwwfyacW6/iy+++KjbALz//vs644wzJEl5eXnKzs5OGKNgMKhNmzYljHN1dbVKS0vNmjVr1igej2vUqFFmzfr16xWJRMya4uJinXPOOerevfsJO7+TSUNDg+z2xLcnh8OheDwuibE+ETpzTDvsZ0mrlvye5p599lnD4/EYixcvNnbu3GncdtttRnp6esKVG/jclClTDJ/PZ6xdu9b49NNPza2hocGsmTx5stGvXz9jzZo1xltvvWX4/X7D7/eb7S2X944ZM8bYsmWLsXLlSqNXr17HvLx35syZxnvvvWc88sgjp9Xlvcdy5FVIhsE4d4TNmzcbTqfT+O1vf2vs2bPHeOaZZ4yUlBTjL3/5i1kzf/58Iz093fj73/9uvPvuu8Z3vvOdY16GOmzYMGPTpk3G66+/bpx11lkJl6FWV1cbWVlZxo033mhs377dePbZZ42UlJRT9tLeY5k4caLRp08f8zLq559/3ujZs6cxa9Yss4axbr3a2lrjnXfeMd555x1DkvGHP/zBeOedd4yPPvrIMIzOG9M33njDcDqdxu9//3vjvffeM371q19xGXVneOihh4x+/foZbrfbuOiii4yNGzd2dZdOWpKOuT311FNmTWNjo/GTn/zE6N69u5GSkmJ897vfNT799NOE43z44YfG2LFjjeTkZKNnz57Gz372MyMSiSTUvPbaa8YFF1xguN1u48wzz0x4jdPRFwMM49wxXn75ZePcc881PB6PMXDgQOPxxx9PaI/H48Yvf/lLIysry/B4PMaVV15p7N69O6Hm0KFDxg033GCkpaUZXq/X+PGPf2zU1tYm1GzdutW45JJLDI/HY/Tp08eYP3/+CT+3k0kwGDTuuOMOo1+/fkZSUpJx5plnGr/4xS8SLs1lrFvvtddeO+bP5IkTJxqG0bljunTpUuPss8823G63MWTIEGPFihWtPh+bYRxxa0MAAAALYA0MAACwHAIMAACwHAIMAACwHAIMAACwHAIMAACwHAIMAACwHAIMAACwHAIMAACwHAIMAACwHAIMAACwHAIMAACwHAIMAACwnP8fo/9sAD1mCssAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lossi)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Build the same MLP layer but with fully pytorch code (nn.Linear(), etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network dimensions\n",
    "n_in = 784\n",
    "n_hidden = 200\n",
    "n_out = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, Y_tr = train_input, train_target\n",
    "X_test, Y_test = test_input, test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList((\n",
    "            nn.Linear(n_in, n_hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(n_hidden, n_out),\n",
    "            nn.Tanh()\n",
    "        ))\n",
    "\n",
    "    def __call__(self, x):\n",
    "        out = x\n",
    "        for layer in self.layers:\n",
    "            out = layer(out)\n",
    "        return out\n",
    "\n",
    "    def __parameters__(self):\n",
    "        return [p for layer in self.layers for p in layer.parameters()]\n",
    "\n",
    "\n",
    "model = MLP()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =      0\tloss=0.13648\taccuracy (train, test): 0.10200\t0.20800\n",
      "step =   1000\tloss=0.00061\taccuracy (train, test): 1.00000\t0.87100\n",
      "step =   2000\tloss=0.00001\taccuracy (train, test): 1.00000\t0.86800\n",
      "step =   3000\tloss=0.00013\taccuracy (train, test): 1.00000\t0.87400\n",
      "step =   4000\tloss=0.00003\taccuracy (train, test): 1.00000\t0.87100\n",
      "step =   5000\tloss=0.00001\taccuracy (train, test): 1.00000\t0.87300\n",
      "step =   6000\tloss=0.00001\taccuracy (train, test): 1.00000\t0.87200\n",
      "step =   7000\tloss=0.00001\taccuracy (train, test): 1.00000\t0.87400\n",
      "step =   8000\tloss=0.00002\taccuracy (train, test): 1.00000\t0.87600\n",
      "step =   9000\tloss=0.00000\taccuracy (train, test): 1.00000\t0.87400\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "num_epochs = 10000\n",
    "\n",
    "for n in range(num_epochs):\n",
    "    y_pred = model(X_tr)\n",
    "    loss = loss_fn(y_pred, Y_tr)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if n % 1000 == 0: \n",
    "        with torch.no_grad():\n",
    "            acc_train = compute_accuracy(y_pred, Y_tr)\n",
    "            y_test_preds = model(X_test)\n",
    "            acc_test = compute_accuracy(y_test_preds, Y_test)\n",
    "            print(f'step = {n:6d}\\tloss={loss.item():.5f}\\taccuracy (train, test): {acc_train:.5f}\\t{acc_test:.5f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise: try to improve accuracy!\n",
    "\n",
    "In this improved version, I switched from a tanh-based MSE setup to a more standard classification configuration using ReLU activations and a CrossEntropy loss on integer class labels. The network capacity was increased by using a 256-unit hidden layer, and I introduced dropout with probability 0.2 after the hidden layer to reduce overfitting. I also replaced full-batch training with mini-batches of size 128 and optimized the model using AdamW with a learning rate of 1e-3, which typically leads to faster and more stable convergence on MNIST. Finally, I applied Kaiming initialization to the linear layers to keep the activations well-scaled when using ReLU, improving training stability and often yielding higher accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_tr_labels = train_target.argmax(dim=1)\n",
    "Y_test_labels = test_target.argmax(dim=1)\n",
    "\n",
    "X_tr, X_test = train_input, test_input\n",
    "n_in = 784\n",
    "n_hidden = 256\n",
    "n_out = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved MLP\n",
    "\n",
    "class ImprovedMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList((\n",
    "            nn.Linear(n_in, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(n_hidden, n_out),\n",
    "        ))\n",
    "\n",
    "    def __call__(self, x):\n",
    "        out = x\n",
    "        for layer in self.layers:\n",
    "            out = layer(out)\n",
    "        return out\n",
    "\n",
    "    def __parameters__(self):\n",
    "        return [p for layer in self.layers for p in layer.parameters()]\n",
    "\n",
    "model = ImprovedMLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in model.modules():\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def compute_accuracy_labels(logits, labels):\n",
    "    preds = torch.argmax(logits, dim=1)\n",
    "    return (preds == labels).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =   0\tloss = 1.6714\taccuracy (train, test): 0.8030\t0.7240\n",
      "epoch =  20\tloss = 0.0282\taccuracy (train, test): 1.0000\t0.8660\n",
      "epoch =  40\tloss = 0.0085\taccuracy (train, test): 1.0000\t0.8680\n",
      "epoch =  60\tloss = 0.0035\taccuracy (train, test): 1.0000\t0.8740\n",
      "epoch =  80\tloss = 0.0019\taccuracy (train, test): 1.0000\t0.8720\n",
      "epoch = 100\tloss = 0.0014\taccuracy (train, test): 1.0000\t0.8740\n",
      "epoch = 120\tloss = 0.0010\taccuracy (train, test): 1.0000\t0.8730\n",
      "epoch = 140\tloss = 0.0008\taccuracy (train, test): 1.0000\t0.8760\n",
      "epoch = 160\tloss = 0.0008\taccuracy (train, test): 1.0000\t0.8780\n",
      "epoch = 180\tloss = 0.0005\taccuracy (train, test): 1.0000\t0.8790\n",
      "epoch = 200\tloss = 0.0004\taccuracy (train, test): 1.0000\t0.8770\n",
      "epoch = 220\tloss = 0.0004\taccuracy (train, test): 1.0000\t0.8750\n",
      "epoch = 240\tloss = 0.0003\taccuracy (train, test): 1.0000\t0.8770\n",
      "epoch = 260\tloss = 0.0002\taccuracy (train, test): 1.0000\t0.8760\n",
      "epoch = 280\tloss = 0.0003\taccuracy (train, test): 1.0000\t0.8730\n",
      "epoch = 300\tloss = 0.0002\taccuracy (train, test): 1.0000\t0.8770\n",
      "epoch = 320\tloss = 0.0002\taccuracy (train, test): 1.0000\t0.8770\n",
      "epoch = 340\tloss = 0.0001\taccuracy (train, test): 1.0000\t0.8780\n",
      "epoch = 360\tloss = 0.0002\taccuracy (train, test): 1.0000\t0.8810\n",
      "epoch = 380\tloss = 0.0001\taccuracy (train, test): 1.0000\t0.8770\n",
      "epoch = 400\tloss = 0.0001\taccuracy (train, test): 1.0000\t0.8800\n",
      "epoch = 420\tloss = 0.0001\taccuracy (train, test): 1.0000\t0.8800\n",
      "epoch = 440\tloss = 0.0001\taccuracy (train, test): 1.0000\t0.8800\n",
      "epoch = 460\tloss = 0.0001\taccuracy (train, test): 1.0000\t0.8750\n",
      "epoch = 480\tloss = 0.0001\taccuracy (train, test): 1.0000\t0.8770\n",
      "epoch = 500\tloss = 0.0001\taccuracy (train, test): 1.0000\t0.8790\n",
      "epoch = 520\tloss = 0.0001\taccuracy (train, test): 1.0000\t0.8820\n",
      "epoch = 540\tloss = 0.0000\taccuracy (train, test): 1.0000\t0.8810\n",
      "epoch = 560\tloss = 0.0001\taccuracy (train, test): 1.0000\t0.8850\n",
      "epoch = 580\tloss = 0.0000\taccuracy (train, test): 1.0000\t0.8730\n",
      "epoch = 600\tloss = 0.0000\taccuracy (train, test): 1.0000\t0.8800\n",
      "epoch = 620\tloss = 0.0000\taccuracy (train, test): 1.0000\t0.8810\n",
      "epoch = 640\tloss = 0.0669\taccuracy (train, test): 0.9920\t0.8490\n",
      "epoch = 660\tloss = 0.0011\taccuracy (train, test): 1.0000\t0.8820\n",
      "epoch = 680\tloss = 0.0002\taccuracy (train, test): 1.0000\t0.8940\n",
      "epoch = 700\tloss = 0.0003\taccuracy (train, test): 1.0000\t0.8900\n",
      "epoch = 720\tloss = 0.0001\taccuracy (train, test): 1.0000\t0.8870\n",
      "epoch = 740\tloss = 0.0001\taccuracy (train, test): 1.0000\t0.8870\n",
      "epoch = 760\tloss = 0.0001\taccuracy (train, test): 1.0000\t0.8840\n",
      "epoch = 780\tloss = 0.0002\taccuracy (train, test): 1.0000\t0.8920\n",
      "epoch = 800\tloss = 0.0001\taccuracy (train, test): 1.0000\t0.8840\n",
      "epoch = 820\tloss = 0.0001\taccuracy (train, test): 1.0000\t0.8870\n",
      "epoch = 840\tloss = 0.0001\taccuracy (train, test): 1.0000\t0.8890\n",
      "epoch = 860\tloss = 0.0001\taccuracy (train, test): 1.0000\t0.8860\n",
      "epoch = 880\tloss = 0.0002\taccuracy (train, test): 1.0000\t0.8900\n",
      "epoch = 900\tloss = 0.0001\taccuracy (train, test): 1.0000\t0.8880\n",
      "epoch = 920\tloss = 0.0002\taccuracy (train, test): 1.0000\t0.8840\n",
      "epoch = 940\tloss = 0.0003\taccuracy (train, test): 1.0000\t0.8730\n",
      "epoch = 960\tloss = 0.0098\taccuracy (train, test): 1.0000\t0.8680\n",
      "epoch = 980\tloss = 0.0025\taccuracy (train, test): 1.0000\t0.8910\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_epochs = 1000\n",
    "batch_size = 128\n",
    "num_samples = X_tr.shape[0]\n",
    "num_batches = math.ceil(num_samples / batch_size)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    perm = torch.randperm(num_samples)\n",
    "    X_tr_shuffled = X_tr[perm]\n",
    "    Y_tr_shuffled = Y_tr_labels[perm]\n",
    "\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    for b in range(num_batches):\n",
    "        start = b * batch_size\n",
    "        end = min((b + 1) * batch_size, num_samples)\n",
    "        xb = X_tr_shuffled[start:end]\n",
    "        yb = Y_tr_shuffled[start:end]\n",
    "\n",
    "        logits = model(xb)\n",
    "        loss = loss_fn(logits, yb)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item() * (end - start)\n",
    "\n",
    "    epoch_loss /= num_samples\n",
    "\n",
    "    if epoch % 20 == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            train_logits = model(X_tr)\n",
    "            acc_train = compute_accuracy_labels(train_logits, Y_tr_labels)\n",
    "\n",
    "            test_logits = model(X_test)\n",
    "            acc_test = compute_accuracy_labels(test_logits, Y_test_labels)\n",
    "\n",
    "        print(\n",
    "            f\"epoch = {epoch:3d}\\t\"\n",
    "            f\"loss = {epoch_loss:.4f}\\t\"\n",
    "            f\"accuracy (train, test): {acc_train:.4f}\\t{acc_test:.4f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are slightly better (0.874 → 0.891), but they require significantly more training time. With such a small dataset, it appears challenging to achieve a substantial improvement in performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to the previous optimization, this version explicitly targets overfitting by reducing model capacity and increasing regularization. I replaced the 256-unit hidden layer with a smaller 64-unit layer and kept a single hidden layer to limit the network’s ability to memorize the training set. I added stronger regularization through a higher dropout rate (0.3) on the hidden activations and an explicit L2 penalty via AdamW’s weight decay parameter. Finally, I introduced early stopping based on validation (test) accuracy, so training stops automatically once the model stops improving, preventing unnecessary overfitting while keeping training time under control. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "Y_tr_labels = train_target.argmax(dim=1)\n",
    "Y_test_labels = test_target.argmax(dim=1)\n",
    "\n",
    "X_tr, X_test = train_input, test_input\n",
    "n_in = 784\n",
    "n_hidden = 64\n",
    "n_out = 10\n",
    "\n",
    "def compute_accuracy_labels(logits, labels):\n",
    "    preds = torch.argmax(logits, dim=1)\n",
    "    return (preds == labels).float().mean().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model: small regularized MLP\n",
    "\n",
    "class SmallDropoutMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(n_in, n_hidden)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.fc2 = nn.Linear(n_hidden, n_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = SmallDropoutMLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaiming init for ReLU\n",
    "for m in model.modules():\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "\n",
    "# Optimizer + L2 regularization (weight decay)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 0\tloss=2.2285\tacc_train=0.6300\tacc_test=0.5150\n",
      "epoch=20\tloss=0.1609\tacc_train=0.9910\tacc_test=0.8530\n",
      "epoch=40\tloss=0.0759\tacc_train=1.0000\tacc_test=0.8620\n",
      "Early stopping triggered\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training loop with early stopping\n",
    "\n",
    "\n",
    "num_epochs = 1000\n",
    "batch_size = 128\n",
    "num_samples = X_tr.shape[0]\n",
    "num_batches = math.ceil(num_samples / batch_size)\n",
    "\n",
    "best_test = 0.0\n",
    "patience = 5\n",
    "no_improve = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    perm = torch.randperm(num_samples)\n",
    "    X_tr_shuffled = X_tr[perm]\n",
    "    Y_tr_shuffled = Y_tr_labels[perm]\n",
    "\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    for b in range(num_batches):\n",
    "        start = b * batch_size\n",
    "        end = min((b + 1) * batch_size, num_samples)\n",
    "        xb = X_tr_shuffled[start:end]\n",
    "        yb = Y_tr_shuffled[start:end]\n",
    "\n",
    "        logits = model(xb)\n",
    "        loss = loss_fn(logits, yb)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item() * (end - start)\n",
    "\n",
    "    epoch_loss /= num_samples\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_logits = model(X_tr)\n",
    "        acc_train = compute_accuracy_labels(train_logits, Y_tr_labels)\n",
    "\n",
    "        test_logits = model(X_test)\n",
    "        acc_test = compute_accuracy_labels(test_logits, Y_test_labels)\n",
    "    \n",
    "    if epoch%20 ==0:\n",
    "        print(\n",
    "            f\"epoch={epoch:2d}\\tloss={epoch_loss:.4f}\\t\"\n",
    "            f\"acc_train={acc_train:.4f}\\tacc_test={acc_test:.4f}\"\n",
    "        )\n",
    "\n",
    "    if acc_test > best_test + 1e-3:\n",
    "        best_test = acc_test\n",
    "        no_improve = 0\n",
    "    else:\n",
    "        no_improve += 1\n",
    "        if no_improve >= patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training starts in a mildly underfitting regime and quickly converges to a very confident classifier. By epoch 40, the model reaches 100% training accuracy and about 86% test accuracy, after which early stopping prevents further overfitting on the 1000-sample training set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
